[
{
	"uri": "/vi/1-cicd/1.1-setupgithubandecr/",
	"title": "Chuáº©n bá»‹ Github Repo ",
	"tags": [],
	"description": "",
	"content": "Trong bÃ i nÃ y, cÃ¡c báº¡n sáº½ chuáº©n bá»‹ cÃ¡c files cáº§n thiáº¿t cho cÃ¡c bÃ i sau. MÃ¬nh sáº½ Ä‘i qua tá»«ng pháº§n. Trong bÃ i lab nÃ y, mÃ¬nh sáº½ sá»­ dá»¥ng VSCode Ä‘á»ƒ chuáº©n bá»‹ Ä‘áº§y Ä‘á»§ cÃ¡c file á»Ÿ mÃ´i trÆ°á»ng local vÃ  Ä‘áº©y lÃªn Github. MÃ¬nh cÅ©ng sá»­ dÃ¹ng Console Ä‘á»ƒ deploy kiáº¿n trÃºc lÃªn cloud. á» pháº§n 2 cá»§a bÃ i workshop, mÃ¬nh sáº½ chá»‰ cÃ¡ch cÃ¡c báº¡n cÃ³ thá»ƒ deploy lÃªn báº±ng CDK (Cloud Development Kit) náº¿u báº¡n muá»‘n há»c thÃªm vá» IaC.\nChuáº©n bá»‹ crawler vÃ  push lÃªn Github TrÆ°á»›c háº¿t, báº¡n cáº§n chuáº©n bá»‹ cÃ¡c file crawler vÃ  Ä‘áº©y lÃªn Github. ÄÃ¢y sáº½ lÃ  crawler mÃ  chÃºng ta sáº½ deploy lÃªn cloud. Báº¡n hÃ£y vÃ o link Github sau: Github Crawler. Sau khi vÃ o rá»“i hÃ£y clone repo nÃ y vá» mÃ¡y cá»§a báº¡n. Báº¡n cÃ³ thá»ƒ clone báº±ng cÃ¡ch cháº¡y lá»‡nh sau:\ngit clone -b indeed-scraper https://github.com/MinhThieu145/Job-Scraper-Home.git Náº¿u nhÆ° báº¡n bá»‹ lá»—i á»Ÿ cÃ¢u lá»‡nh trÃªn, hÃ£y thá»­ dÃ¹ng:\ngit --version Náº¿u nhÆ° báº¡n tháº¥y káº¿t quáº£ tráº£ vá» hiá»ƒn thá»‹ rÃµ git version. ThÃ¬ báº¡n Ä‘Ã£ cÃ i git thÃ nh cÃ´ng. Náº¿u khÃ´ng, báº¡n cáº§n cÃ i git trÆ°á»›c khi clone repo. Báº¡n cÃ³ thá»ƒ cÃ i git báº±ng cÃ¡ch tham kháº£o link sau CÃ¡ch cÃ i Github cho VsCode. Sau khi clone hoÃ n táº¥t, báº¡n sáº½ cÃ³ 1 repo nhÆ° sau:\nğŸ“¦Job-Scraper-Home â”£ ğŸ“‚.git â”£ ğŸ“‚__pycache__ â”£ ğŸ“‚result â”£ ğŸ“œ.gitignore â”£ ğŸ“œbuildspec.yml â”£ ğŸ“œdockerfile â”£ ğŸ“œexploration.ipynb â”£ ğŸ“œjob_description_analyzer.py â”£ ğŸ“œmain.py â”£ ğŸ“œrequirements.txt â”— ğŸ“œscraper.py MÃ¬nh sáº½ Ä‘i qua tá»«ng file vÃ  folder mÃ  báº¡n cáº§n biáº¿t trong repo nÃ y:\n1. main.py vÃ  scraper.py Äáº§u tiÃªn lÃ  file main.py. File cÃ³ nhiá»‡m vá»¥ cháº¡y file scraper.py vÃ  chá»©a káº¿t quáº£ trong 1 folder tÃªn lÃ  result (sáº½ táº¡o folder má»›i náº¿u khÃ´ng tá»“n táº¡i). Sau cÃ¹ng, script sáº½ Ä‘áº©y táº¥t cáº£ files trong folder result lÃªn S3.\n# import indeed scraper import scraper # import analyze data function import job_description_analyzer # some other libraries import os import pandas as pd # main function def main(): # clean the result folder # get current dir current_dir = os.getcwd() # get the result folder if exit try: # if the result folder exists result_dir = os.path.join(current_dir, \u0026#39;result\u0026#39;) # delete all the files in the result folder for file in os.listdir(result_dir): os.remove(os.path.join(result_dir, file)) except: # create a new folder called result os.mkdir(\u0026#39;result\u0026#39;) result_dir = os.path.join(current_dir, \u0026#39;result\u0026#39;) # run the scraper scraper.main() # get the result from a folder called result # loop through the result folder for file in os.listdir(result_dir): # if that is a csv file if file.endswith(\u0026#39;.csv\u0026#39;): # read with pandas df = pd.read_csv(os.path.join(result_dir, file)) # if the dataframe is not empty if not df.empty: # pass that to the analyze data function job_description_analyzer.main(df=df, df_name=file.split(\u0026#39;.\u0026#39;)[0]) if __name__ == \u0026#34;__main__\u0026#34;: main() Náº¿u báº¡n Ä‘á»c kÄ© code, báº¡n sáº½ tháº¥y main.py loop qua táº¥t cáº£ file Ä‘uÃ´i .csv trong folder result vÃ  gá»i 1 function khÃ¡c trong job_description_analyzer.py trÆ°á»›c khi Ä‘áº©y lÃªn S3. LÃ½ do lÃ  vÃ¬ mÃ¬nh Ä‘Ã£ cáº¯t ngáº¯n repo Ä‘i nhiá»u. Ban Ä‘áº§u crawler sáº½ cÃ³ nhiá»‡m vá»¥ nhÆ° sau.\nmain.py sáº½ lÃªn S3 Ä‘á»ƒ tÃ¬m cÃ¡c crawlers (má»—i website lÃ  1 crawler khÃ¡c nhau) vÃ  cháº¡y cÃ¡c crawler nÃ y. CÃ¡c crawler nÃ y sau khi cháº¡y xong Ä‘á»u sáº½ lÆ°u káº¿t quáº£ vÃ o folder result. - Sau Ä‘Ã³, file job_description_analyzer.py cÃ³ nhiá»‡m vá»¥ extract nhá»¯ng tá»« khoÃ¡ vÃ  nhá»¯ng thÃ´ng tin quan trá»ng báº±ng GPT API, trÆ°á»›c khi lÆ°u káº¿t quáº£ láº¡i Cuá»‘i cÃ¹ng, cáº£ káº¿t quáº£ scrap ban Ä‘áº§u vÃ  sau khi xá»­ lÃ½ Ä‘Æ°á»£c Ä‘áº©y lÃªn S3. Do quÃ¡ trÃ¬nh nÃ y khÃ¡ lÃ¢u, dá»… há»ng vÃ  khÃ´ng hiá»‡u quáº£ khi gáº§n nhÆ° xá»­ lÃ½ hoÃ n toÃ n báº±ng code. Náº¿u báº¡n muá»‘n thá»­ lÃ m láº¡i, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng AWS Step Function vÃ  AWS SNS Ä‘á»ƒ decouple cÃ¡c pháº§n, nháº±m Ä‘áº£m báº£o thá»© tá»± thá»±c hiá»‡n vÃ  Ä‘á»™ á»•n Ä‘á»‹nh cá»§a Pipeline. NhÆ°ng trong bÃ i lab nÃ y mÃ¬nh sáº½ khÃ´ng Ä‘i qua pháº§n Ä‘Ã³\n2. dockerfile vÃ  requirements.txt ÄÃ¢y lÃ  2 files cáº§n thiáº¿t Ä‘á»ƒ cÃ³ thá»ƒ build 1 docker image tá»« code. Trong File dockerfile, mÃ¬nh Ä‘Ã£\nSá»­ dá»¥ng based image lÃ  Ubuntu:22.04. NhÆ°ng báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng nhá»¯ng base image khÃ¡c, miá»…n lÃ  cÃ³ cÃ i sáºµn Python3. Náº¿u khÃ´ng báº¡n sáº½ pháº£i tá»± cÃ i Ä‘áº·t Python3 CÃ i Ä‘áº·t vÃ  update pip Ä‘á»ƒ táº£i cÃ i cÃ¡c package cáº§n thiáº¿t cho crawler. TÃªn cá»§a cÃ¡c package nÃ y Ä‘Æ°á»£c lÆ°u trong file requirements.txt. Trong bÃ i lab nÃ y, mÃ¬nh Ä‘Ã£ sá»­ dá»¥ng boto3 Ä‘á»ƒ cÃ³ thá»ƒ gá»i cÃ¡c API cá»§a AWS, openai Ä‘á»ƒ cÃ³ thá»ƒ gá»i API cá»§a GPT3 (cÃ³ thá»ƒ bá» vÃ¬ khÃ´ng dÃ¹ng ná»¯a), pandas Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u, selenium Ä‘á»ƒ cÃ³ thá»ƒ cháº¡y crawler vÃ  webdriver_manager Ä‘á»ƒ cÃ³ thá»ƒ tá»± Ä‘á»™ng táº£i driver cho selenium. Táº¥t cáº£ cÃ¡c packages nÃ y Ä‘á»u Ä‘Æ°á»£c lÆ°u trong file requirements.txt. Báº¡n cÃ³ thá»ƒ thÃªm bá»›t cÃ¡c packages nÃ y tÃ¹y theo Ã½ muá»‘n. boto3==1.26.165 openai==0.27.7 pandas==1.5.3 selenium==4.10.0 tenacity==8.2.2 webdriver_manager==3.8.6 CÃ i Ä‘áº·t Chrome browser cho image. Cuá»‘i cÃ¹ng lÃ  Copy cÃ¡c file vÃ o docker image Báº¡n cÃ³ thá»ƒ Ä‘á»c dockerfile cá»§a mÃ¬nh á»Ÿ Ä‘Ã¢y\n# based image: Ubuntubased. BTW, for the PYTHON:3.9 like you used last time. It used the Debianbased image FROM public.ecr.aws/docker/library/ubuntu:22.04 # install a few things RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ bash \\ git \\ curl \\ software-properties-common \\ pip \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # workdir WORKDIR /srv # okay now pip RUN apt-get -y update RUN pip install --upgrade pip # Copy the requirements.txt file first, for separate dependency resolving and downloading COPY requirements.txt . RUN pip install -r requirements.txt # Install chrome broswer RUN curl -sS -o - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - RUN echo \u0026#34;deb http://dl.google.com/linux/chrome/deb/ stable main\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list.d/google-chrome.list RUN apt-get -y update RUN apt-get -y install google-chrome-stable # add the main.py COPY main.py . # add scraper COPY scraper.py . # add job_description_analyzer COPY job_description_analyzer.py . ENTRYPOINT [ \u0026#34;python3\u0026#34; , \u0026#34;main.py\u0026#34; ] 3. buildspec.yml CÃ²n 1 file ná»¯a mÃ  báº¡n cáº§n chÃº Ã½, Ä‘Ã³ lÃ  file buildspec.yml. File nÃ y cá»±c kÃ¬ quan trá»ng, vÃ¬ nÃ³ hÆ°á»›ng dáº«n cho AWS Codebuild cÃ¡ch build image cá»§a báº¡n. Buildspec Ä‘Æ°á»£c chia lÃ m 3 phase, pre_build, build vÃ  post_build.\nversion: 0.2 phases: pre_build: commands: - echo \u0026#34;Logging in to ECR\u0026#34; - aws --version - AWS_DEFAULT_REGION=us-east-1 - AWS_ACCOUNT_ID=238101178196 - IMAGE_TAG=latest - REPOSITORY_URI=238101178196.dkr.ecr.us-east-1.amazonaws.com/indeed-scraper - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com build: commands: - echo \u0026#34;Building the Docker image...\u0026#34; - docker build -t $REPOSITORY_URI:$IMAGE_TAG . - docker push $REPOSITORY_URI:$IMAGE_TAG post_build: commands: - echo \u0026#34;Updating ECS service...\u0026#34; - echo \u0026#34;End of script\u0026#34; artifacts: files: - \u0026#39;**/*\u0026#39; name: artifacts Trong phase pre_build, mÃ¬nh Ä‘Ã£ lÆ°u cÃ¡c biáº¿n mÃ´i trÆ°á»ng nhÆ° sau:\nAWS_DEFAULT_REGION: region mÃ  báº¡n dÃ¹ng cho bÃ i workshop nÃ y, mÃ¬nh dÃ¹ng us-east-1 (virginia) AWS_ACCOUNT_ID: Account ID tÃ i khoáº£n AWS cá»§a ban, cÃ³ thá»ƒ tÃ¬m Ä‘Æ°á»£c á»Ÿ pháº§n account IMAGE_TAG: Tag cá»§a image mÃ  báº¡n muá»‘n láº¥y trong ECR. Trong quÃ¡ trÃ¬nh build, báº¡n sáº½ update image nhiá»u láº§n, má»—i láº§n lÃ  tag + 1. NÃªn tag latest giÃºp báº¡n láº¥y image má»›i nháº¥t REPOSITORY_URI: link cá»§a ECR repo chá»©a image, mÃ¬nh sáº½ táº¡o ngay á»Ÿ phÃ­a dÆ°á»›i. DÃ²ng cuá»‘i cÃ¹ng cá»§a phase lÃ  Ä‘á»ƒ mÃ¬nh authenticate script cá»§a mÃ¬nh, giÃºp mÃ¬nh cÃ³ thá»ƒ thá»±c hiá»‡n cÃ¡c lá»‡nh trong Docker nhÆ° Push hay Pull image tá»« Ecr. Trong phase build, mÃ¬nh sáº½ build image vÃ  push lÃªn ECR repo.\ndocker build -t $REPOSITORY_URI:$IMAGE_TAG . mÃ¬nh build image vÃ  set tag lÃ  latest. ÄÃ¢y lÃ  biáº¿n IMAGE_TAG mÃ¬nh set tá»« trÆ°á»›c. Nhá»› Ä‘á»«ng quÃªn cÃ³ 1 dáº¥u cháº¥m sau chá»¯ IMAGE_TAG Ä‘áº¥y. docker push $REPOSITORY_URI:$IMAGE_TAG mÃ¬nh push Docker image mÃ¬nh vá»«a build lÃªn Ecr repo. á» Ä‘oáº¡n nÃ y, náº¿u lÃ m theo mÃ¬nh thÃ¬ báº¡n sáº½ bá»‹ vÆ°á»›n máº¯c do mÃ¬nh chÆ°a táº¡o repo, vÃ¬ váº­y báº¡n cÃ³ thá»ƒ Ä‘á»ƒ trá»‘ng biáº¿n nÃ y, vÃ  Ä‘á»c tiáº¿p pháº§n sau Ä‘á»ƒ biáº¿t cÃ¡ch táº¡o repo. Cuá»‘i cÃ¹ng lÃ  phase post_build. MÃ¬nh chá»‰ log ra console Ä‘á»ƒ thÃ´ng bÃ¡o hoÃ n thÃ nh. Phase nÃ y hoÃ n toÃ n khÃ´ng thá»±c hiá»‡n lá»‡nh gÃ¬ cáº£.\nDeploy Github repo lÃªn Github. Sau khi hoÃ n thÃ nh viá»‡c chuáº©n bá»‹ cÃ¡c file, viá»‡c tiáº¿p theo lÃ  Ä‘áº©y repo lÃªn Github. Äáº§u tiÃªn, báº¡n cáº§n má»Ÿ folder mÃ  báº¡n vá»«a clone repo vá». Trong VSCode sáº½ nhÃ¬n nhÆ° tháº¿ nÃ y Kiá»ƒm tra xem báº¡n Ä‘Ã£ cÃ³ git chÆ°a báº±ng git --version. Tiáº¿p Ä‘áº¿n, báº¡n cáº§n remove file .git khá»i folder do folder váº«n liÃªn káº¿t vá»›i repo Github cá»§a mÃ¬nh. DÃ¹ng lá»‡nh nÃ y Ä‘á»ƒ remove file .git rm -rf .git. Sau Ä‘Ã³ báº¡n cáº§n táº¡o repo má»›i trÃªn Github cá»§a mÃ¬nh. git init -b main Ä‘á»ƒ khá»Ÿi táº¡o repo má»›i. git add . Ä‘á»ƒ add táº¥t cáº£ cÃ¡c file trong folder vÃ o repo git commit -m \u0026quot;Initial commit\u0026quot; Ä‘á»ƒ commit cÃ¡c file vá»«a add vÃ o repo LÃªn tÃ i khoáº£n github cá»§a báº¡n, táº¡o 1 repo má»›i vÃ  copy URL git remote add origin \u0026lt;URL\u0026gt; Ä‘á»ƒ add repo má»›i vÃ o local repo cá»§a báº¡n git push -u origin main Ä‘á»ƒ push repo lÃªn Github. Náº¿u báº¡n bá»‹ lá»—i, hÃ£y thá»­ git push -f origin main Ä‘á»ƒ force push. Sau khi push xong, báº¡n cÃ³ thá»ƒ tháº¥y repo cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c update "
},
{
	"uri": "/vi/1-cicd/",
	"title": "Chuáº©n bá»‹ vÃ  thiáº¿t káº¿ CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": "Giá»›i thiá»‡u tá»•ng quÃ¡t ChÃ o má»«ng cÃ¡c báº¡n Ä‘áº¿n vá»›i pháº§n Ä‘áº§u tiÃªn cá»§a workshop. Trong pháº§n nÃ y, mÃ¬nh sáº½ Ä‘i qua tá»«ng bÆ°á»›c Ä‘á»ƒ chuáº©n bá»‹ crawler vÃ  Ä‘áº©y lÃªn Github, thiáº¿t káº¿ CodeBuild Ä‘á»ƒ cÃ³ thá»ƒ tá»± Ä‘á»™ng build vÃ  deploy docker image lÃªn AWS ECR\n"
},
{
	"uri": "/vi/",
	"title": "Giá»›i thiá»‡u vÃ  Chuáº©n bá»‹",
	"tags": [],
	"description": "",
	"content": "Giá»›i thiá»‡u tá»•ng quÃ¡t ChÃ o má»«ng cÃ¡c báº¡n Ä‘áº¿n vá»›i Workshop 1. Trong bÃ i workshop nÃ y, mÃ¬nh sáº½ thiáº¿t káº¿ kiáº¿n trÃºc cho 1 crawler Ä‘Æ¡n giáº£n Ä‘á»ƒ báº¡n cÃ³ thá»ƒ crawl job postings trÃªn Indeed. BÃ i lab nÃ y sáº½ chia lÃ m 3 pháº§n chÃ­nh:\n1. Thiáº¿t káº¿ Pipeline CI/CD Pháº§n 1 cá»§a bÃ i lab sáº½ lÃ  vá» qui trÃ¬nh CI/CD cá»§a crawler. MÃ¬nh sáº½ sá»­ dá»¥ng CodeBuild Ä‘á»ƒ tá»± Ä‘á»™ng láº¥y code tá»« Githubm tá»« Ä‘Ã³ build Docker image cho crawler vÃ  tá»± Ä‘á»™ng Ä‘áº©y image vÃ o ECR. Pháº§n kiáº¿n trÃºc sáº½ thiáº¿t káº¿ nhÆ° sau:\n2. Thiáº¿t káº¿ kiáº¿n trÃºc cho crawler Pháº§n 2 cá»§a bÃ i lab, cÅ©ng lÃ  pháº§n chÃ­nh, sáº½ lÃ  vá» viá»‡c cháº¡y crawler dÆ°á»›i dáº¡ng Docker image báº±ng Fargate. MÃ¬nh cÅ©ng sáº½ cung cáº¥p code cho crawler. Crawler Ä‘Æ°á»£c viáº¿t báº±ng Python vÃ  Selenium. Báº¡n cÅ©ng cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘á»ƒ táº¡o crawler cho cÃ¡c website khÃ¡c hoáº·c sá»­a Ä‘á»•i crawler hiá»‡n táº¡i theo Ã½ muá»‘n. Pháº§n kiáº¿n trÃºc bao gá»“m AWS EventBridge Ä‘á»ƒ cÃ³ thá»ƒ cháº¡y crawler theo lá»‹ch trÃ¬nh, AWS Lambda Ä‘á»ƒ gá»­i job definition vÃ o job queue trong AWS Batch. Sau khi hoÃ n thÃ nh sáº½ chá»©a káº¿t quáº£ vÃ o S3. Kiáº¿n trÃºc thiáº¿t káº¿ nhÆ° sau:\n3. Thiáº¿t káº¿ 1 webapp front-end Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£ Pháº§n 3 cá»§a bÃ i lab sáº½ chÃº trá»ng vÃ o viá»‡c thiáº¿t káº¿ 1 high-availability (sáºµn sÃ ng cao) webapp Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£ crawler. MÃ¬nh sáº½ sá»­ dá»¥ng Streamlit vÃ  viáº¿t báº±ng Python. Webapp sáº½ Ä‘Æ°á»£c Ä‘áº·t trong Ec2. Kiáº¿n trÃºc thiáº¿t káº¿ nhÆ° sau: "
},
{
	"uri": "/vi/1-cicd/1.2-setupecrrepo/",
	"title": "Setup repo cho AWS ECR",
	"tags": [],
	"description": "",
	"content": "ChÃºc má»«ng báº¡n Ä‘Ã£ chuáº©n bá»‹ xong Github repo cá»§a mÃ¬nh. ÄÃ¢y sáº½ repo Ä‘á»ƒ chá»©a crawler cá»§a báº¡n vÃ  dÃ¹ng trong CI/CD pipeline sau nÃ y. Trong bÃ i nÃ y, mÃ¬nh sáº½ táº¡o AWS ECR repo Ä‘á»ƒ chá»©a image sau khi build xong tá»« Codebuild. SÆ¡ lÆ°á»£c vá» dá»‹ch vá»¥ AWS ECR: ÄÃ¢y lÃ  1 dá»‹ch vá»¥ cá»§a AWS, cho phÃ©p quáº£n lÃ½, lÆ°u trá»¯ vÃ  triá»ƒn khai cÃ¡c container. Dá»‹ch vá»¥ nÃ y Ä‘Æ°á»£c dÃ¹ng vá»›i cÃ¡c dá»‹ch vá»¥ cháº¡y Conatiner nhÆ° AWS ECS, AWS EKS, AWS Fargate, AWS Batch,\u0026hellip; Trong bÃ i workshop nÃ y thÃ¬ mÃ¬nh dÃ¹ng AWS ECR cÃ¹ng vá»›i AWS Batch\nTáº¡o repo trÃªn AWS ECR LÃªn AWS, tÃ¬m AWS ECR -\u0026gt; chá»n Create repository. CÃ¡c setting báº¡n Ä‘á»ƒ nhÆ° sau\nVisibility: Chá»n cháº¿ Ä‘á»™ private. MÃ¬nh tá»«ng gáº·p lá»—i khÃ´ng thá»ƒ pull image Ä‘Æ°á»£c náº¿u Ä‘á»ƒ lÃ  public, nÃªn recommend Ä‘áº·t lÃ  private Repository name: Äáº·t tÃªn cho repo, báº¡n cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c link repo. Trong pháº§n Repository name, báº¡n sáº½ tháº¥y má»™t chá»— Ä‘á»ƒ Ä‘iá»n tÃªn. Pháº§n cÃ²n láº¡i chÃ­nh lÃ  URI dáº«n tá»›i repo cá»§a báº¡n. MÃ¬nh sáº½ Ä‘áº·t tÃªn repo lÃ  indeed-scraper, nÃªn link dáº«n tá»›i repo cá»§a mÃ¬nh sáº½ lÃ :\n238101178196.dkr.ecr.us-east-1.amazonaws.com/indeed-scraper Báº¡n cÃ³ thá»ƒ tháº¥y link Ä‘Æ°á»£c tÃ¡ch lÃ m nhiá»u pháº§n. Trong Ä‘Ã³, dÃ£y sá»‘ Ä‘á»©ng Ä‘áº§u 238101178196 lÃ  account Id cá»§a báº¡n. Sau chá»¯ ecr lÃ  region sá»­ dá»¥ng. MÃ¬nh sá»­ dá»¥ng region lÃ  us-east-1. Cuá»‘i cÃ¹ng lÃ  tÃªn báº¡n tá»± Ä‘áº·t, cá»§a mÃ¬nh lÃ  indeed-scraper\ná» 3 options cÃ²n láº¡i, báº¡n cÃ³ thá»ƒ Ä‘á»ƒ lÃ  disable Sau khi táº¡o xong, báº¡n cÃ³ thá»ƒ copy URI cá»§a repo vá»«a táº¡o vÃ  paste vÃ o file buildspec.yml á»Ÿ bÆ°á»›c 2. ÄÃ¢y lÃ  pháº§n mÃ¬nh báº£o Ä‘á»ƒ trá»‘ng ban nÃ£y do chÆ°a táº¡o repo "
},
{
	"uri": "/vi/2-runtask/2.1-awsbatch/",
	"title": "Thiáº¿t káº¿ AWS Batch",
	"tags": [],
	"description": "",
	"content": "Trong bÆ°á»›c nÃ y, chÃºng ta sáº½ setup 1 AWS Batch hoÃ n chá»‰nh Ä‘á»ƒ cháº¡y job. Äá»ƒ sá»­ dá»¥ng AWS Batch, báº¡n cáº§n táº¡o cÃ¡c components mÃ  mÃ¬nh Ä‘Ã£ Ä‘á» cáº­p á»Ÿ bÃ i trÆ°á»›c:\nCompute Environments Job Queues Job Definitions Batch Wizard Äá»ƒ thuáº­n tiá»‡n hÆ¡n thÃ¬ nÃªn sá»­ dá»¥ng wizard thay vÃ¬ táº¡o tá»«ng components riÃªng láº». VÃ o AWS Batch, chá»n Wizard. Náº¿u báº¡n muá»‘n cÃ³ nhiá»u lá»±a chá»n cÃ³ thá»ƒ dÃ¹ng EC2, hoáº·c EKS náº¿u dÃ¹ng Kubernete. NhÆ°ng Ä‘á»ƒ thuáº­n tiá»‡n, mÃ¬nh sáº½ dÃ¹ng Fargate. Compute Environment Chá»n tÃªn cho compute env Spot Instance cÃ³ thá»ƒ giÃºp tiáº¿t kiá»‡m chi phÃ­, tháº¿ nhÆ°ng nhá»¯ng task cháº¡y báº±ng spot instance cÃ³ thá»ƒ bá»‹ ngáº¯t Ä‘oáº¡n giá»¯a chá»«ng, chá»‰ nÃªn dÃ¹ng náº¿u task ngáº¯n hoáº·c cÃ³ thá»ƒ thay thá»ƒ bá»Ÿi nhá»¯ng job khÃ¡c. MÃ¬nh sáº½ chá»n khÃ´ng trong bÃ i nÃ y. Äá»“ng thá»i chá»n vCPU tá»‘i Ä‘a, cÃ³ thá»ƒ Ä‘á»ƒ 4 vCPU. Äáº¿n bÆ°á»›c Network Configuration, báº¡n cÃ³ thá»ƒ setup nhÆ° sau\nTáº¡o 1 VPC vá»›i 1 public subnet Nhá»› táº¡o thÃªm Internet Gateway vÃ  Route table Ä‘á»ƒ Subnet truy cáº­p Ä‘Æ°á»£c vÃ o internet Táº¡o 1 security group cho compute env, má»Ÿ outbound traffic ra internet (default lÃ  má»Ÿ rá»“i nÃªn khÃ´ng cáº§n sá»­a) ThÃªm cÃ¡c pháº§n Ä‘Ã£ táº¡o vÃ o compute env Chá»n next Ä‘á»ƒ táº¡o compute env Job Queue Chá»n tÃªn cho job queue Äáº·t Priority lÃ  1. ÄÃ¢y lÃ  thá»© tá»± Æ°u tiÃªn, trong trÆ°á»ng há»£p báº¡n cÃ³ nhiá»u job queue trong cÃ¹ng má»™t compute env, job queue cÃ³ priority cao sáº½ Ä‘Æ°á»£c cháº¡y trÆ°á»›c. Job Definition Chá»n tÃªn vÃ  timeout cho job definition. Timeout lÃ  thá»i gian cháº¡y tá»‘i Ä‘a cá»§a 1 job. Náº¿u job cháº¡y quÃ¡ thá»i gian nÃ y thÃ¬ sáº½ bá»‹ dá»«ng. MÃ¬nh Æ°á»›c lÆ°á»£ng job cá»§a mÃ¬nh cáº§n Ã­t hÆ¡n 15 phÃºt nÃªn mÃ¬nh Ä‘á»ƒ 15 phÃºt (900s). Fargate, báº¡n Ä‘á»ƒ version lÃ  LATEST, báº­t Public IP vÃ¬ job cáº§n truy cáº­p vÃ o Internet. Ephemeral storage lÃ  dung lÆ°á»£ng cá»§a Fargate, Ä‘á»ƒ tá»« 21GB Ä‘áº¿n 200GB. Execution role Ä‘á»ƒ giÃºp cho task cá»§a báº¡n cÃ³ thá»ƒ truy cáº­p vÃ o ECR Ä‘á»ƒ pull image tá»« Ä‘Ã³, Ä‘á»c Secret tá»« Secret Manager vÃ  1 vÃ i role low level. trong Container configuration, á»Ÿ pháº§n image, báº¡n cáº§n vÃ o ECR, copy URI cá»§a ECR repo mÃ  báº¡n táº¡o trÆ°á»›c Ä‘Ã³ Paste vÃ o pháº§n Image cá»§a Batch Wizard vÃ  thÃªm latest vÃ o phÃ­a sau Ä‘á»ƒ cÃ³ thá»ƒ láº¥y image má»›i nháº¥t Pháº§n tiáº¿p theo lÃ  command. Báº¡n cÃ³ thá»ƒ thÃªm command cho Docker Image cá»§a báº¡n. Command nÃ y sáº½ khÃ´ng overwrite CMD hay ENTRYPOINT trong docker cá»§a báº¡n, mÃ  sáº½ thÃªm vÃ o. VÃ¬ mÃ¬nh khÃ´ng cáº§n thÃªm gÃ¬ nÃªn sáº½ Ä‘á»ƒ default, cÃ¢u lá»‡nh default chá»‰ Ä‘á»ƒ in ra Hello World CÃ³ váº» hÆ¡i kÃ¬ láº¡ khi cÃ³ táº­n 2 role trong pháº§n job definition, tuy nhiÃªn, theo lá»i giáº£i thÃ­ch táº¡i Ä‘Ã¢y. Náº¿u Task cá»§a báº¡n cáº§n quyá»n high level hÆ¡n nhÆ° truy cáº­p S3(nhá»¯ng quyá»n mÃ  khÃ´ng pháº£i task nÃ o cÅ©ng cáº§n), thÃ¬ báº¡n cÃ³ thá»ƒ Ä‘á»ƒ á»Ÿ job role, cÃ²n nhá»¯ng quyá»n tháº¥p hÆ¡n nhÆ° pull image tá»« ECR thÃ¬ cÃ³ thá»ƒ cá»‘ Ä‘á»‹nh á»Ÿ execution role. Task cá»§a mÃ¬nh cáº§n truy cáº­p vÃ o S3 nÃªn sáº½ táº¡o 1 role Full Access S3, tuy nhiÃªn náº¿u khÃ´ng cáº§n gÃ¬ ngoÃ i cháº¡y task thÃ¬ báº¡n cÃ³ thá»ƒ Ä‘Ãª trá»‘ng (chá»n None). Äá»“ng thá»i báº¡n cáº§n chá»n vCPU vÃ  Memory Chá»n tÃªn cho Job cá»§a báº¡n. Khi mÃ  cháº¡y thÃ¬ tÃªn nÃ y sáº½ Ä‘Æ°á»£c hiá»ƒn thá»‹. Sau khi hoÃ n thÃ nh, chá»n Review vÃ  Create Resource. Váº­y lÃ  báº¡n Ä‘Ã£ hoÃ n thÃ nh viá»‡c setup AWS Batch. Äá»ƒ kiá»ƒm tra, báº¡n cÃ³ thá»ƒ vÃ o Job Definition vÃ  chá»n Submit new Job\n"
},
{
	"uri": "/vi/3-frontendapp/3.1-vpc/",
	"title": "Thiáº¿t káº¿ mÃ´i trÆ°á»ng máº¡ng",
	"tags": [],
	"description": "",
	"content": "BÆ°á»›c Ä‘áº§u tiÃªn chÃ­nh lÃ  thiáº¿t káº¿ mÃ´i trÆ°á»ng máº¡ng cho app. NhÆ° Ä‘Ã£ Ä‘á»ƒ cáº­p trÆ°á»›c Ä‘Ã³, Ä‘Ã¢y lÃ  nhá»¯ng tÃ i nguyÃªn mÃ¬nh sáº½ táº¡o:\n2 public subnet, 2 private subnet 1 VPC 1 Internet Gateway 1 NAT Gateway (cÃ³ thá»ƒ táº¡o 2 NAT Gateway náº¿u muá»‘n an toÃ n hÆ¡n - má»—i NAT á»Ÿ 1 subnet) S3 Endpoint Ä‘á»ƒ truy cáº­p S3 mÃ  khÃ´ng cáº§n Ä‘i qua NAT Gateway Setup VPC vÃ  subnet Chá»n VPC, Create VPC. Chá»n vÃ o option VPC and more. Äáº·t tÃªn cho VPC. Báº¡n cÃ³ thá»ƒ Ä‘á»ƒ defaul CIDR: 10.0.0.0/16, báº¡n cÅ©ng cÃ³ thá»ƒ thay CIDR Ä‘á»ƒ tÄƒng giáº£m sá»‘ lÆ°á»£ng IP trong VPC. Báº¡n cÃ³ thá»ƒ Ä‘á»ƒ IPV6 nhÆ° default (khÃ´ng dÃ¹ng IPV6) Number of Availability Zones: sá»‘ AZ mÃ  VPC sáº½ Ä‘Æ°á»£c táº¡o. Theo diagram, mÃ¬nh sáº½ Ä‘á»ƒ 2 AZ. Báº¡n cÅ©ng cÃ³ thá»ƒ chá»n Customize AZs Ä‘á»ƒ chá»n sang nhá»¯ng AZ khÃ¡c (default lÃ  us-east-1a vÃ  us-east-1b náº¿u dÃ¹ng us-east-1) Number of public subnets: bao nhiÃªu public subnet trong VPC. MÃ¬nh cáº§n 2 public subnet (má»—i AZ 1 public subnet) nÃªn sáº½ Ä‘á»ƒ 2. Äá»“ thá»‹ á»Ÿ bÃªn pháº£i cÅ©ng chá»‰ rÃµ ra tá»«ng pháº§n cá»§a public subnet: má»—i AZ cÃ³ 1 subnet, subnet Ä‘Æ°á»£c thÃ´ng qua Route table Ä‘á»ƒ ná»‘i Ä‘áº¿n Internet Gateway. Number of private subnets: bao nhiÃªu private subnet trong VPC. MÃ¬nh cÅ©ng cáº§n 2 private (1 AZ 1 private). Náº¿u chá»n 4, báº¡n cÃ³ thá»ƒ tháº¥y sá»‘ lÆ°á»£ng private subnet tÄƒng lÃªn 1 á»Ÿ má»—i AZ Customize subnets CIDR blocks: Báº¡n cÃ³ thá»ƒ Ä‘iá»u chá»‰nh thÃ´ng sá»‘ nÃ y Ä‘á»ƒ tÄƒng giáº£m sá»‘ Ä‘á»‹a chá»‰ IP má»—i subnet. Hiá»‡n táº¡i, má»—i submet cÃ³ 4096 IP NAT gateways ($) ÄÃ¢y lÃ  pháº§n khÃ¡ tá»‘n kÃ©m. Náº¿u muá»‘n an toÃ n vÃ  Ä‘Ãºng theo diagram, báº¡n cÃ³ thá»ƒ chá»n 1 per AZ Ä‘á»ƒ má»—i AZ cÃ³ 1 NAT. Báº¡n cÅ©ng cÃ³ thá»ƒ chá»n In 1 AZ Ä‘á»ƒ chá»‰ táº¡o 1 NAT gateway cho cáº£ 2 private subnet.\nVPC endpoints NÃªn chá»n Ä‘á»ƒ giáº£m chi phÃ­ truy cáº­p S3. Do náº¿u báº¡n dÃ¹ng boto3 mÃ  khÃ´ng cÃ³ Endpoint thÃ¬ pháº£i buá»™c Ä‘i qua NAT (do dá»¯ liá»‡u truyá»n ra internet). Viá»‡c cÃ³ Endpoint sáº½ giáº£m chi phÃ­ nÃ y NAT (náº¿u thá»±c sá»± khÃ´ng cáº§n Internet) vÃ  phÃ­ data transfer.\nDNS option chá»n cáº£ 2 options\nChá»n Create VPC Ä‘á»ƒ hoÃ n thÃ nh.\n"
},
{
	"uri": "/vi/1-cicd/1.3-deployoncloud/",
	"title": "Deploy CI/CD pipeline lÃªn AWS",
	"tags": [],
	"description": "",
	"content": "Sau khi hoÃ n thÃ nh cÃ¡c bÆ°á»›c chuáº©n bá»‹, thÃ¬ báº¡n cÅ©ng Ä‘Ã£ cÃ³ Ä‘áº§y Ä‘á»§ cÃ¡c file cáº§n thiáº¿t Ä‘á»ƒ deploy CI/CD pipeline lÃªn AWS. Trong bÃ i nÃ y, mÃ¬nh sáº½ hÆ°á»›ng dáº«n báº¡n cÃ¡ch deploy CI/CD pipeline lÃªn AWS báº±ng cÃ¡ch sá»­ dá»¥ng AWS Codebuild\nSÆ¡ lÆ°á»£c vá» dá»‹ch vá»¥ AWS Codebuild: AWS Codebuild cho phÃ©p tá»± Ä‘á»™ng build, test vÃ  containerize code cá»§a báº¡n. Codebuild cÃ³ thá»ƒ dÃ¹ng vá»›i AWS CodePipeline Ä‘á»ƒ tá»± Ä‘á»™ng deploy sau khi build. Tuy nhiÃªn trong bÃ i nÃ y mÃ¬nh chá»‰ build vÃ  push image lÃªn ECR thÃ´i.\nTáº¡o Codebuild Project TÃ¬m Codebuild trong AWS, chá»n Create build project\nTrong pháº§n Project configuration, Ä‘iá»n tÃªn project vÃ  Description á» pháº§n Source, chá»n Github lÃ  provider á» pháº§n Repository, chá»n Connect to Github vÃ  chá»n repo mÃ  báº¡n Ä‘Ã£ táº¡o á»Ÿ bÆ°á»›c trÆ°á»›c. Báº¡n cÃ³ thá»ƒ bá»‹ yÃªu cáº§u connect vá»›i Github á»Ÿ bÆ°á»›c nÃ y, nháº­p password vÃ o káº¿t ná»‘i thÃ´i. Tiáº¿p Ä‘áº¿n pháº§n Primary source webhook events, tick options webhook Ä‘á»ƒ build báº±ng webhook, chá»n single build vÃ  event type lÃ  PUSH Trong pháº§n Environment, chá»n Managed image (Docker image Ä‘Ã£ bao gá»“m Operating System rá»“i, nÃªn pháº§n nÃ y tháº­t táº¿ khÃ´ng cáº§n thiáº¿t. NhÆ°ng náº¿u báº¡n khÃ´ng dÃ¹ng Docker vÃ  cáº§n 1 vÃ i packages thÃ¬ cÃ³ thá»ƒ dÃ¹ng Custom Image). Operating System chá»n Ubuntu, Runtime lÃ  Standard vÃ  version chá»n latest 7.0. Environment type chá»n Linux khÃ´ng cÃ³ GPU.\nBáº¡n Ä‘áº·t biá»‡t pháº£i chá»n Privileged á»Ÿ pháº§n Additional configuration. Náº¿u khÃ´ng chá»n thÃ¬ sáº½ khÃ´ng thá»ƒ push image lÃªn ECR Ä‘Æ°á»£c.\nChá»n New Role á» pháº§n Buildspec, chá»n Use a buildspec file, vÃ  Ä‘á»ƒ trá»‘ng Ã´ name, vÃ¬ chá»‰ cáº§n Ä‘áº·t láº¡i tÃªn náº¿u khÃ´ng Ä‘á»ƒ file á»Ÿ root folder hoáº·c dÃ¹ng tÃªn khÃ¡c Nhá»¯ng pháº§n cÃ²n láº¡i Ä‘á»ƒ nguyÃªn vÃ  chá»n Create build project. Váº­y lÃ  báº¡n Ä‘Ã£ hoÃ n táº¥t cÃ¡c bÆ°á»›c Ä‘á»ƒ cÃ³ 1 pipeline tá»± Ä‘á»™ng láº¥y code tá»« Github, buil docker image vÃ  push lÃªn ECR repo.\n"
},
{
	"uri": "/vi/3-frontendapp/3.2-elb/",
	"title": "Táº¡o tÃ i nguyÃªn: ALB vÃ  ASG",
	"tags": [],
	"description": "",
	"content": "Sau khi hoÃ n táº¥t quÃ¡ trÃ¬nh táº¡o VPC, báº¡n cáº§n táº¡o thÃªm cÃ¡c tÃ i nguyÃªn trong VPC. Trong bÃ i nÃ y, mÃ¬nh sáº½ táº¡o nhá»¯ng tÃ i nguyÃªn sau:\nLaunch Template: ÄÃ¢y giá»‘ng nhÆ° 1 báº£n váº½. Nhá»¯ng instace Ä‘Æ°á»£c táº¡o ra tá»« ASG sáº½ giá»‘ng vá»›i báº£n váº½ nÃ y. VÃ  Ä‘á»ƒ táº¡o ra Launch Template vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c packages cáº§n thiáº¿t, mÃ¬nh sáº½ táº¡o sáºµn má»™t AMI SÆ¡ lÆ°á»£c vá» Amazon Machine Image (AMI): CÃ³ thá»ƒ hiá»ƒu AMI lÃ  báº£n váº½ cá»§a instance. Khi táº¡o 1 EC2 instance má»›i, báº¡n Ä‘Æ°á»£c há»i chá»n AMI. Äa pháº§n báº¡n sáº½ dÃ¹ng base image, nhá»¯ng AMI Ä‘Æ°á»£c cung cáº¥p bá»Ÿi AWS nhÆ° lÃ  ubuntu, linux hay window. Tuy nhiÃªn, náº¿u muá»‘n EC2 Ä‘Æ°á»£c táº¡o vá»›i cÃ¡c package cÃ³ sáºµn, ta cÃ³ thá»ƒ táº¡o custom image.\nASG: Táº¡o ASG báº±ng Launch Template phÃ­a trÃªn ALB: Táº¡o ALB Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng request Táº¡o Custom AMI vÃ  Launch Template Khi cÃ¡c Instance Ä‘Æ°á»£c khá»Ÿi táº¡o tá»« ASG, chÃºng cáº§n 1 khuÃ´ng máº«u (template). Äá»ƒ táº¡o ra 1 launch template, trÆ°á»›c tiÃªn ta cáº§n táº¡o 1 custom AMI vá»›i táº¥t cáº£ package cáº§n thiáº¿t.\nVÃ o Ec2, chá»n Launch Template rá»“i chá»n Create launch template Äáº·t tÃªn cho template rá»“i chá»n option Auto Scaling guidance Ä‘á»ƒ thuáº­n tiá»‡n tÃ­ch há»£p vá»›i ASG sau nÃ y. Chá»n AMI, báº¥m vÃ o Browse more AMIs Nháº­p sá»‘ 238101178196 vÃ o thanh tÃ¬m kiáº¿m rá»“i chá»n Community AMI, báº¡n nÃªn tháº¥y 1 AMI vá»›i tÃªn nhÆ° hÃ¬nh dÆ°á»›i. ÄÃ¢y lÃ  AMI mÃ¬nh public, chá»¯a sáºµn cÃ¡c file cháº¡y server. Náº¿u thá»±c hiá»‡n Ä‘Ãºng nhÆ° cÃ¡c bÆ°á»›c trÆ°á»›c, Ä‘áº·t biá»‡t lÃ  cÃ¡ch Ä‘áº·t tÃªn bucket cá»§a S3, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng mÃ  khÃ´ng cáº§n thay Ä‘á»•i gÃ¬. BÃªn trong AMI cÃ i sáºµn 1 streamlit server vá»›i cá»•ng 8501, Ä‘á»“ng thá»i lÆ°u káº¿t quáº£ vÃ o S3 trong Bucket tÃªn lÃ  job-description-process, vÃ  láº¥y tá»« folder tÃªn indeed-scraper\nChá»n select AMI Ä‘Ã³, báº¡n sáº½ Ä‘Æ°á»£c Ä‘Æ°a láº¡i chá»— template Ä‘á»ƒ tiáº¿p tá»¥c. á» pháº§n Instance Type chá»n t2.micro. á» pháº§n Key pair chá»n 1 key pair mÃ  báº¡n Ä‘Ã£ cÃ³ sáºµn Ä‘á»ƒ sau nÃ y thuáº­n tiá»‡n SSH vÃ o instance (táº¥t nhiÃªn lÃ  pháº£i qua Bastion Host) Pháº§n Network Settings báº¡n cÃ³ thá»ƒ Ä‘á»ƒ trá»‘ng (khÃ´ng chá»n gÃ¬ cáº£) Báº¡n cÃ³ thá»ƒ Ä‘á»ƒ nhá»¯ng pháº§n cÃ²n láº¡i default.\ná» Advanced details, expand ra vÃ  chá»n vÃ o Create new IAM profile, do Frontend app cáº§n 1 vÃ i roles (Truy cáº­p S3 vÃ  Ä‘á»c Ec2). Táº¡o 1 role má»›i cÃ³ cÃ¡c policies nhÆ° sau Sau khi táº¡o xong, quay láº¡i template, reload (cÃ¡i mÅ©i tÃªn trÃ²n bÃªn cáº¡nh) Ä‘á»ƒ tháº¥y role vá»«a táº¡o vÃ  chá»n Sau Ä‘Ã³ chá»n Create launch template Ä‘á»ƒ táº¡o template.\nTáº¡o Auto Scaling Group VÃ o Ec2, kÃ©o xuá»‘ng cuá»‘i cÃ¹ng Ä‘á»ƒ tháº¥y Ä‘Æ°á»£c ALB. Chá»n Create Auto Scaling Group vÃ  chá»n tÃªn cho ASG. Sau Ä‘Ã³ trong pháº§n Launch Template, chá»n Template mÃ  báº¡n táº¡o ban nÃ£y, chá»n version lÃ  Latest á» tab Network, chá»n VPC mÃ  báº¡n táº¡o ban nÃ£y. Trong VPC Ä‘Ã³, chá»n cáº£ hai Private Subnet mÃ  báº¡n táº¡o ban nÃ£y. Ta sáº½ Ä‘áº·t á»©ng dá»¥ng á»Ÿ Private Subnet Ä‘á»ƒ tÄƒng tÃ­nh báº£o máº­t, Public Subnet chá»‰ Ä‘á»ƒ táº¡o NAT Gateway vÃ  Ä‘áº·t Bastion Host. Báº¥m next á» tab Load Balancing, chá»n Attach to new load balancer . BÃªn trong tab má»›i má»Ÿ, chá»n Application Load Balancer, chá»n tÃªn cho Load Balancer vÃ  chá»n Internet-facing Káº¿ Ä‘áº¿n lÃ  pháº§n Network mapping, VPC sáº½ Ä‘Æ°á»£c giá»¯ nguyÃªn nhÆ° cá»§a ASG (táº¥t nhiÃªn, ELB Ä‘á»ƒ handle traffic vÃ o ASG nÃªn cáº§n pháº£i chung VPC rá»“i). Báº¡n cáº§n chá»n 2 Public Subnet Ä‘á»ƒ Ä‘áº·t ELB á» pháº§n Listener vÃ  Routing, chá»n Port lÃ  8501 cho Streamlit, vÃ  chá»n Create a target Group vÃ  Ä‘áº·t tÃªn cho target group Trong pháº§n Health checks, chá»n option Turn on Elastic Load Balancing health checks. Äá»“ng thá»i Ä‘áº·t Health check grace period lÃ  300s. ÄÃ¢y lÃ  thá»i gian Æ°á»›c lÆ°á»£ng Ä‘á»ƒ Ec2 khá»Ÿi Ä‘á»™ng (Ä‘Ã¢y lÃ  cÃ¡ch Ä‘á»ƒ Ec2 instance trÃ¡nh bá»‹ destroy khi chÆ°a khá»Ÿi Ä‘á»™ng xong. Náº¿u User Data khiáº¿n instance máº¥t thá»i gian khá»Ÿi Ä‘á»™ng, hÃ£y Æ°á»›c lÆ°á»£ng thá»i gian cáº§n thiáº¿t Ä‘á»ƒ khá»Ÿi Ä‘á»™ng á»Ÿ Ä‘Ã¢y). Äá»ƒ pháº§n Additional settings nhÆ° default vÃ  báº¥m Next\nGroupsize bao gá»“m 3 pháº§n: Maximum capacity Ä‘á»ƒ chá»‰ sá»‘ instance tá»‘i Ä‘a, Minimum capacity lÃ  sá»‘ instance tá»‘i thiá»ƒu, Desired capacity lÃ  sá»‘ instance mÃ  ASG cá»‘ giá»¯ á»Ÿ má»©c Ä‘Ã³. Äá»ƒ trá»‘ng pháº§n Scaling policies vÃ  chá»n Next\nBá» qua pháº§n Add notifications vÃ  chá»n Next. Bá» qua tags vÃ  next rá»“i chá»n Create Auto Scaling Group\n"
},
{
	"uri": "/vi/2-runtask/",
	"title": "Thiáº¿t káº¿ AWS Batch vÃ  S3 Ä‘á»ƒ cháº¡y crawler vÃ  lÆ°u káº¿t quáº£",
	"tags": [],
	"description": "",
	"content": "Giá»›i thiá»‡u tá»•ng quan ChÃºc má»«ng cÃ¡c báº¡n Ä‘Ã£ hoÃ n thÃ nh pháº§n 1 cá»§a workshop. Trong pháº§n nÃ y, mÃ¬nh sáº½ thiáº¿t káº¿ AWS Batch Ä‘á»ƒ cÃ³ thá»ƒ tá»± Ä‘á»™ng láº¥y cÃ¡c image tá»« ECR repo mÃ  mÃ¬nh Ä‘Ã£ lÃ m á»Ÿ pháº§n trÆ°á»›c vÃ  cháº¡y theo lá»‹ch trÃ¬nh cÃ³ sáºµn. MÃ¬nh cÅ©ng sáº½ táº¡o S3 bucket Ä‘á»ƒ lÆ°u káº¿t quáº£. Nhá»¯ng dá»‹ch vá»¥ mÃ  mÃ¬nh sáº½ sá»­ dá»¥ng trong bÃ i nÃ y:\nAWS Batch: Äá»ƒ cháº¡y task crawler cá»§a mÃ¬nh AWS S3: Äá»ƒ lÆ°u trá»¯ káº¿t quáº£ AWS EventBridge: Äá»ƒ cháº¡y task theo lá»‹ch trÃ¬nh. Do náº¿u chá»‰ dÃ¹ng AWS Batch, báº¡n sáº½ pháº£i submit job thá»§ cÃ´ng. NÃªn mÃ¬nh sáº½ dÃ¹ng EventBridge Ä‘á»ƒ tá»± Ä‘á»™ng submit job vÃ o Batch theo lá»‹ch trÃ¬nh cÃ³ sáºµn AWS Lambda: Tuy EventBridge cÃ³ thá»ƒ Ä‘áº·t lá»‹ch trÃ¬nh. Tuy nhiÃªn, Ä‘á»ƒ cÃ³ thÃªm nhiá»u tÃ­nh nÄƒng, mÃ¬nh sáº½ dÃ¹ng Lambda Ä‘á»ƒ submit job vÃ o Batch. Lambda sáº½ Ä‘Æ°á»£c trigger bá»Ÿi EventBridge má»™t cÃ¡ch vÃ´ cÃ¹ng dá»… dÃ ng. VÃ  tá»± Lambda, mÃ¬nh sáº½ dÃ¹ng boto3 Ä‘á»ƒ káº¿t ná»‘i vá»›i Batch vÃ  submit job. Giá»›i thiá»‡u vá» AWS Batch AWS Batch lÃ  1 dá»‹ch vá»¥ serverless, cho phÃ©p báº¡n cháº¡y cÃ¡c Batch job. AWS Batch sáº½ tá»± Ä‘á»™ng scale cÃ¡c node nhá» hÆ¡n. GiÃºp báº¡n tiáº¿t kiá»‡m chi phÃ­ vÃ  cháº¡y job nhanh hÆ¡n. MÃ¬nh sáº½ Ä‘i qua tá»«ng pháº§n cá»§a AWS Batch:\nCompute Environment: ÄÃ¢y lÃ  nÆ¡i Ä‘á»ƒ báº¡n chá»n compute resource phÃ¹ há»£p vá»›i nhu cáº§u cá»§a báº¡n. Do Batch lÃ  dá»‹ch vá»¥ serverless nÃªn báº¡n sáº½ khÃ´ng pháº£i setup quÃ¡ nhiá»u Job queue: 1 queue Ä‘á»ƒ chá»©a cÃ¡c job. Khi báº¡n submit job vÃ o Batch, cÃ¡c job sáº½ náº±m trong queue Job definition: lÃ  Ä‘á»‹nh nghÄ©a cá»§a job. Báº¡n cÃ³ thá»ƒ tÆ°á»Ÿng tÆ°á»£ng Ä‘Ã¢y lÃ  báº£n váº½ cá»§a job mÃ  báº¡n muá»‘n thá»±c hiá»‡n. Khi muá»‘n thá»±c hiá»‡n job definition nÃ y, thÃ¬ báº¡n submit nÃ³ vÃ o queue. Giá»›i thiá»‡u vá» S3 ÄÃ¢y lÃ  dá»‹ch vá»¥ khÃ¡ ná»•i tiáº¿ng cá»§a AWS. S3 lÃ  dá»‹ch vá»¥ lÆ°u trá»¯ dáº¡ng object. S3 cÃ³ thá»ƒ lÆ°u cÃ¡c Ä‘á»‹nh dáº¡ng file khÃ¡c nhau, code, video hay hÃ¬nh áº£nh,\u0026hellip;\n"
},
{
	"uri": "/vi/6-cdk/6.1-cicd/",
	"title": "Thiáº¿t káº¿ CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": "Trong pháº§n lab trÆ°á»›c, báº¡n Ä‘Ã£ há»c cÃ¡ch táº¡o pipeline cho crawler vá»›i Codebuild. Trong pháº§n nÃ y, mÃ¬nh sáº½ sá»­ dá»¥ng CDK Ä‘á»ƒ thá»±c hiá»‡n Ä‘iá»u tÆ°Æ¡ng tá»±. Trong repo mÃ  báº¡n clone vá», trong folder workshop1 cÃ³ 1 file python lÃ : cicd_stack.py. ÄÃ¢y lÃ  file setup CI/CD pipeline cho crawler. MÃ¬nh sáº½ Ä‘i qua tá»«ng pháº§n trong file nÃ y. Äáº§u tiÃªn lÃ  tá»•ng quan file:\nfrom aws_cdk import ( # Duration, Stack, # aws codebuild aws_codebuild as codebuild, # aws iam aws_iam as iam, ) from constructs import Construct # Some pther lib import os # load the data for the CodeBuild from environment variables from dotenv import load_dotenv load_dotenv() GITHUB_OWNER = os.getenv(\u0026#34;OWNER\u0026#34;) GITHUB_REPO = os.getenv(\u0026#34;REPO\u0026#34;) GITHUB_BRANCH = os.getenv(\u0026#34;BRANCH\u0026#34;) # please use this line to add credential to the CodeBuild # aws codebuild import-source-credentials --server-type GITHUB --auth-type PERSONAL_ACCESS_TOKEN --token \u0026lt;token_value\u0026gt; # The personal Token need to have enough permission to access the repo class CICDStack(Stack): def __init__(self, scope: Construct, construct_id: str, **kwargs) -\u0026gt; None: super().__init__(scope, construct_id, **kwargs) # Create the CodeBuild Project # Create Github Source github_source = codebuild.Source.git_hub( owner=f\u0026#34;{GITHUB_OWNER}\u0026#34;, repo=f\u0026#34;{GITHUB_REPO}\u0026#34;, webhook=True, branch_or_ref=f\u0026#34;{GITHUB_BRANCH}\u0026#34;, # there are an option called webhook_filters: that is for the Webhook Event Filter on AWS. Leave it as default ) # Create the role for the CodeBuild Project codebuild_role = iam.Role( scope=self, id=\u0026#34;JobScrapingCICDRole\u0026#34;, role_name=\u0026#34;JobScrapingCICDRole\u0026#34;, assumed_by=iam.ServicePrincipal(\u0026#34;codebuild.amazonaws.com\u0026#34;), # add the full S3 access to the role managed_policies=[ iam.ManagedPolicy.from_aws_managed_policy_name( managed_policy_name=\u0026#34;AmazonS3FullAccess\u0026#34; ), # add the full ECR access to the role iam.ManagedPolicy.from_aws_managed_policy_name( managed_policy_name=\u0026#34;AmazonEC2ContainerRegistryFullAccess\u0026#34; ), ] ) # Create the CodeBuild Project codebuild.Project( scope=self, id=\u0026#34;CICDProject\u0026#34;, project_name=\u0026#34;CICDProject\u0026#34;, # add description description=\u0026#34;CodeBuild Project for the CICD for Job Scraping Project\u0026#34;, # set the source source=github_source, # add some environment variables environment=codebuild.BuildEnvironment( # add the Base Environment Variable build_image=codebuild.LinuxBuildImage.STANDARD_7_0, # set the priviledge to true for docker build privileged=True, ), # Create role for the CodeBuild Project role=codebuild_role, ) Chuáº©n bá»‹ cÃ¡c biáº¿n mÃ´i trÆ°á»ng cho Codebuild. Thay vÃ¬ connect trá»±c tiáº¿p vÃ o Github nhÆ° khi sá»­ dá»¥ng console, báº¡n buá»™c pháº£i sá»­ dá»¥ng environment variable Ä‘á»ƒ truyá»n thÃ´ng tin vÃ o Codebuild. MÃ¬nh sáº½ sá»­ dá»¥ng thÆ° viá»‡n dotenv Ä‘á»ƒ load cÃ¡c biáº¿n mÃ´i trÆ°á»ng tá»« file .env, nhÆ°ng báº¡n cÃ³ thá»ƒ Ä‘á»ƒ trong code.\n# load the data for the CodeBuild from environment variables from dotenv import load_dotenv load_dotenv() GITHUB_OWNER = os.getenv(\u0026#34;OWNER\u0026#34;) GITHUB_REPO = os.getenv(\u0026#34;REPO\u0026#34;) GITHUB_BRANCH = os.getenv(\u0026#34;BRANCH\u0026#34;) BÃªn cáº¡nh Ä‘Ã³, mÃ¬nh cÅ©ng import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t cho stack\nfrom aws_cdk import ( # Duration, Stack, # aws codebuild aws_codebuild as codebuild, # aws iam aws_iam as iam, ) from constructs import Construct # Some pther lib import os # load the data for the CodeBuild from environment variables from dotenv import load_dotenv load_dotenv() CÃ²n má»™t bÆ°á»›c ráº¥t quan trá»ng Ä‘á»ƒ báº¡n cháº¡y Ä‘Æ°á»£c Gitbuild, Ä‘Ã³ lÃ  cáº¥p quyá»n access Github cho AWS. Báº¡n cáº§n láº¥y personal access key tá»« Github vÃ  sá»­ dá»¥ng lá»‡nh sau.\naws codebuild import-source-credentials --server-type GITHUB --auth-type PERSONAL_ACCESS_TOKEN --token \u0026lt;token_value\u0026gt; Khi táº¡o personal access tá»« Github, báº¡n cáº§n cáº¥p Ä‘á»§ quyá»n cho AWS. Náº¿u bá»‹ lá»—i thÃ¬ cáº§n kiá»ƒm tra láº¡i quyá»n cá»§a token\nTáº¡o Github Source á» pháº§n console thÃ¬ báº¡n chá»n Source tá»« console nhÆ° trong áº£nh: NhÆ°ng trong CDK, báº¡n cáº§n táº¡o Github Source báº±ng code. Báº¡n cÃ³ thá»ƒ tham kháº£o thÃªm táº¡i Github Source.\n# Create Github Source github_source = codebuild.Source.git_hub( owner=f\u0026#34;{GITHUB_OWNER}\u0026#34;, repo=f\u0026#34;{GITHUB_REPO}\u0026#34;, webhook=True, branch_or_ref=f\u0026#34;{GITHUB_BRANCH}\u0026#34;, # there are an option called webhook_filters: that is for the Webhook Event Filter on AWS. Leave it as default ) Táº¡o Environment Trong console, á»Ÿ tab Environment, báº¡n cáº§n\nChá»n Operating System (mÃ¬nh dÃ¹ng Ubuntu) tick priviledge Ä‘á»ƒ cho phÃ©p docker build Táº¡o 1 role má»›i hay chá»n role cÃ³ sáºµn Trong CDK, Ä‘á»ƒ táº¡o 1 role má»›i\n# Create the role for the CodeBuild Project codebuild_role = iam.Role( scope=self, id=\u0026#34;JobScrapingCICDRole\u0026#34;, role_name=\u0026#34;JobScrapingCICDRole\u0026#34;, assumed_by=iam.ServicePrincipal(\u0026#34;codebuild.amazonaws.com\u0026#34;), # add the full S3 access to the role managed_policies=[ iam.ManagedPolicy.from_aws_managed_policy_name( managed_policy_name=\u0026#34;AmazonS3FullAccess\u0026#34; ), # add the full ECR access to the role iam.ManagedPolicy.from_aws_managed_policy_name( managed_policy_name=\u0026#34;AmazonEC2ContainerRegistryFullAccess\u0026#34; ), ] ) Sau Ä‘Ã³, báº¡n cÃ³ thá»ƒ táº¡o Codebuild Project. CÃ¡c pháº§n nhÆ° operating system, tick priviledge Ä‘á»u cÃ³ thá»ƒ lÃ m á»Ÿ Ä‘Ã¢y. Báº¡n cÃ³ thá»ƒ tháº¥y trong Ä‘oáº¡n code bÃªn dÆ°á»›i, mÃ¬nh Ä‘Ã£ Ä‘áº·t tÃªn, description, gÃ¡n source lÃ  github, táº¡o environment lÃ  Linux Standard 7.0 giá»‘ng vá»›i console, tick priviledge vÃ  chá»n role lÃ  role vá»«a táº¡o.\n# Create the CodeBuild Project codebuild.Project( scope=self, id=\u0026#34;CICDProject\u0026#34;, project_name=\u0026#34;CICDProject\u0026#34;, # add description description=\u0026#34;CodeBuild Project for the CICD for Job Scraping Project\u0026#34;, # set the source source=github_source, # add some environment variables environment=codebuild.BuildEnvironment( # add the Base Environment Variable build_image=codebuild.LinuxBuildImage.STANDARD_7_0, # set the priviledge to true for docker build privileged=True, ), # Create role for the CodeBuild Project role=codebuild_role, ) Váº­y lÃ  báº¡n Ä‘Ã£ hoÃ n táº¥t cÃ´ng Ä‘oáº¡n CI/CD\n"
},
{
	"uri": "/vi/2-runtask/2.2-eventands3/",
	"title": "Táº¡o lá»‹ch trÃ¬nh Ä‘á»ƒ submit job báº±ng EventBridge vÃ  lÆ°u káº¿t quáº£ vÃ o S3",
	"tags": [],
	"description": "",
	"content": "Sau khi hoÃ n thÃ nh bÆ°á»›c trÆ°á»›c, báº¡n Ä‘Ã£ cÃ³ 1 job setup hoÃ n chá»‰nh trÃªn Batch. NhÆ°ng Ä‘á»ƒ cháº¡y job, báº¡n cáº§n submit job. Báº¡n cÃ³ thá»ƒ submit job thá»§ cÃ´ng báº±ng cÃ¡ch vÃ o Batch, chá»n job vÃ  Submit new Job Tuy nhiÃªn, náº¿u báº¡n cáº§n submit job má»—i ngÃ y, hay theo má»™t lá»‹ch trÃ¬nh cá»‘ Ä‘á»‹nh hay theo má»™t trigger nÃ o Ä‘Ã³ thÃ¬ viá»‡c submit job thá»§ cÃ´ng lÃ  khÃ´ng kháº£ thi. VÃ¬ váº­y, chÃºng ta sáº½ táº¡o 1 schedule Ä‘á»ƒ tá»± Ä‘á»™ng submit job. Äá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng Cloudwatch Event vÃ  Lambda Ä‘á»ƒ táº¡o 1 schedule vÃ  submit job.\nTáº¡o Lambda VÃ o Lambda, chá»n Create function CÃ³ thá»ƒ Ä‘á»ƒ lÃ  Default from Scrach do function khÃ¡ Ä‘Æ¡n giáº£n, chá»n tÃªn, Runtime vÃ  Architecture Ä‘á»ƒ lÃ  x86_64 Chá»n Change default execution role do báº¡n cáº§n thÃªm role cho function Ä‘á»ƒ cÃ³ thá»ƒ submit job. VÃ o IAM vÃ o thÃªm policy AWSBatchServiceEventTargetRole cho role Sau khi táº¡o xong role, cÃ³ thá»ƒ chá»n Create function\nSau khi táº¡o xong function, paste Ä‘oáº¡n code sau vÃ o function\nimport boto3 import os def lambda_handler(event, context): # client batch_client = boto3.client(\u0026#39;batch\u0026#39;) # load from the environment variables of lambda job_name = os.getenv(\u0026#34;JOB_NAME\u0026#34;) job_queue = os.getenv(\u0026#34;JOB_QUEUE\u0026#34;) job_definition = os.getenv(\u0026#34;JOB_DEFINITION\u0026#34;) response = batch_client.submit_job( jobName=job_name, jobQueue=job_queue, jobDefinition=job_definition, ) if \u0026#39;jobId\u0026#39; in response: return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#34;Job submitted successfully. Job ID: {response[\u0026#39;jobId\u0026#39;]}\u0026#34; } else: return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: \u0026#39;Failed to submit job to AWS Batch\u0026#39; } Äá»“ng thá»i, báº¡n cáº§n thay cÃ¡c giÃ¡ trá»‹ cá»§a job_name, job_queue vÃ  job_definition báº±ng giÃ¡ trá»‹ tÆ°Æ¡ng á»©ng ban nÃ£y trong AWS Batch\nTáº¡o S3 bucket Ä‘á»ƒ lÆ°u káº¿t quáº£ Trong workshop nÃ y, mÃ¬nh lÆ°u káº¿t quáº£ báº±ng boto3 vÃ o 1 bucket tÃªn lÃ  job-description-process, bÃªn trong bucket Ä‘Ã³, mÃ¬nh sáº½ táº¡o 1 folder tÃªn lÃ  indeed-scraper vÃ  lÆ°u káº¿t quáº£. Báº¡n cáº§n vÃ o file job_description_analyzer.py á»Ÿ github clone ban nÃ£y vÃ  sá»­a giÃ¡ trá»‹ cá»§a BUCKET_NAME_RESULT thÃ nh tÃªn cá»§a riÃªng báº¡n. LÃ½ do lÃ  vÃ¬ S3 lÃ  dá»‹ch vá»¥ global, vÃ  tÃªn bucket pháº£i lÃ  duy nháº¥t, khÃ´ng thá»ƒ trÃ¹ng.\nVÃ o S3, Create bucket Chá»n tÃªn tuá»³ Ã½ vÃ  Ä‘á»ƒ phÃ n cÃ²n láº¡i lÃ  default Chá»n Create bucket\nTáº¡o Event Bridge VÃ o Event Bridge, chá»n Schedules Chá»n Create Schedule Sau khi Ä‘áº·t tÃªn cho schedule, á»Ÿ pháº§n Occurence chá»n Recurring Schedule, Schedule Type lÃ  Cron-based vÃ  Ä‘iá»n Cron nhÆ° sau\n0 6 ? * * * Chá»n Flexible time window lÃ  Off vÃ  chá»n Next Chá»n target lÃ  AWS Lambda vÃ  chá»n Lambda Function vá»«a táº¡o vÃ  Next Äá»ƒ default options á»Ÿ trang tiáº¿p theo, chá»n next vÃ  cuá»‘i cÃ¹ng lÃ  Create sau khi review\n"
},
{
	"uri": "/vi/3-frontendapp/",
	"title": "Táº¡o Webapp Frontend Ä‘á»ƒ xem káº¿t quáº£",
	"tags": [],
	"description": "",
	"content": "Giá»›i thiá»‡u tá»•ng quan Náº¿u báº¡n Ä‘Ã£ Ä‘áº¿n Ä‘Æ°á»£c Ä‘Ã¢y, chÃºc má»«ng báº¡n Ä‘Ã£ gáº§n nhÆ° hoÃ n thÃ nh workshop. á» cÃ¡c pháº§n trÆ°á»›c, Crawler Ä‘Ã£ cÃ³ thá»ƒ cháº¡y theo lá»‹ch trÃ¬nh vÃ  lÆ°u káº¿t quáº£ vÃ o S3. Tuy nhiÃªn, váº«n chÆ°a cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ báº¡n cÃ³ thá»ƒ coi nhá»¯ng káº¿t quáº£ áº¥y má»™t cÃ¡ch thuáº­n tiá»‡n, hay chia sáº» nhá»¯ng káº¿t quáº£ áº¥y vá»›i ngÆ°á»i khÃ¡c. Trong bÃ i nÃ y, mÃ¬nh sáº½ tiáº¿p tá»¥c thiáº¿t káº¿ má»™t webapp báº±ng streamlit Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£ tá»« S3.\nGiá»›i thiá»‡u vá» Streamlit Streamlit lÃ  1 open-source library, dÃ¹ng python Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c webapp. Streamlit chá»§ yáº¿u Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ chia sáº» cÃ¡c káº¿t quáº£ cá»§a data science. Tuy nhiÃªn, báº¡n cÃ³ thá»ƒ dÃ¹ng nÃ³ Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c webapp cho má»¥c Ä‘Ã­ch khÃ¡c. Streamlit cÃ³ thá»ƒ cháº¡y trÃªn local hoáº·c trÃªn cloud. Trong bÃ i nÃ y, mÃ¬nh sáº½ cháº¡y trÃªn Ec2.\nThiáº¿t káº¿ kiáº¿n trÃºc Do kiáº¿n trÃºc pháº§n nÃ y hÆ¡i dÃ i nÃªn mÃ¬nh sáº½ Ä‘i ráº¥t kÄ©. TrÆ°á»›c háº¿t báº¡n hÃ£y Ä‘á»c tháº­t kÄ© diagram architecture cá»§a pháº§n nÃ y. MÃ¬nh sáº½ Ä‘i theo thá»© tá»± mÃ  client sáº½ Ä‘i (tá»©c lÃ  Ä‘i tá»« phÃ­a client tá»›i phÃ­a server). 1. Application Load Balancer Äáº§u tiÃªn, user sáº½ truy cáº­p vÃ o DNS cá»§a Application Load Balancer (ALB) thÃ´ng qua trÃ¬nh duyá»‡t. ALB sáº½ chuyá»ƒn hÆ°á»›ng request Ä‘áº¿n cÃ¡c Auto Scaling Group, tá»« Ä‘Ã³ truy cáº­p vÃ o app Ä‘Æ°á»£c Ä‘áº·t trong private subnet. Báº£n thÃ¢n ALB pháº£i Ä‘Æ°á»£c Ä‘áº·t trong public subnet, vÃ¬ nÃ³ sáº½ nháº­n request tá»« internet. CÃ²n app sáº½ Ä‘Æ°á»£c Ä‘áº·t trong private subnet vÃ¬ nÃ³ sáº½ nháº­n request tá»« ALB.\nSÆ¡ lÆ°á»£c vá» dá»‹ch vá»¥ AWS Elastic Load Balancer (ELB): ELB lÃ  dá»‹ch vá»¥ cÃ¢n báº±ng táº£i cá»§a AWS. NÃ³ cho phÃ©p phÃ¢n phá»‘i cÃ¡c request lÃªn cÃ¡c instance Ä‘á»ƒ Ä‘áº£m báº£m hiá»‡u nÄƒng vÃ  Ä‘á»™ tin cáº­y. ELB cÃ³ thá»ƒ giÃºp cÃ¡c instance khÃ´ng bá»‹ quÃ¡ táº£i báº±ng cÃ¡ch phÃ¢n chia Ä‘á»u request, hay sá»­ dá»¥ng health check Ä‘á»ƒ trÃ¡nh request Ä‘áº¿n cÃ¡c instance bá»‹ lá»—i. Trong bÃ i nÃ y, mÃ¬nh sáº½ sá»­ dá»¥ng loáº¡i cÃ¢n báº±ng táº£i lÃ  Application Load Balancer. ÄÃ¢y lÃ  cÃ¢n báº±ng táº£i á»Ÿ layer 7, há»— trá»£ phÃ¢n phá»‘i dá»±a vÃ o header, protocol cá»§a request.\n2. Auto Scaling Group Sau khi user truy cáº­p Ä‘áº¿n DNS cá»§a ALB, ALB sáº½ chuyá»ƒn hÆ°á»›ng request Ä‘áº¿n cÃ¡c Auto Scaling Group. Auto Scaling Group (ASG) sáº½ chá»‹u trÃ¡ch nhiá»‡m táº¡o ra cÃ¡c instance Ä‘á»ƒ cháº¡y app. CÃ¡c instance Ä‘Æ°á»£c táº¡o ra sáº½ Ä‘Æ°á»£c Ä‘áº·t trong private subnet.\nSÆ¡ lÆ°á»£c vá» dá»‹ch vá»¥ AWS Auto Scaling Group (ASG): AWS ASG lÃ  dá»‹ch vá»¥ cho phÃ©p tá»± Ä‘á»™ng má»Ÿ rá»™ng hoáº·c thu háº¹p instance dá»±a trÃªn Ä‘iá»u kiá»‡n Ä‘áº·t trÆ°á»›c vÃ  tÃ¬nh tráº¡ng cá»§a instance. Auto Scaling Group giÃºp há»‡ thá»‘ng khÃ´ng bá»‹ qÃºa táº£i, cáº¯t giáº£m chi phÃ­ vÃ  tÄƒng availability. Auto Scaling Group sáº½ tá»± Ä‘á»™ng táº¡o thÃªm cÃ¡c EC2 istance, tÄƒng sá»‘ lÆ°á»£ng EC2 instance khi traffic tÄƒng vÃ  giáº£m sá»‘ lÆ°á»£ng EC2 instance khi traffic giáº£m, Ä‘á»“ng thá»i thay tháº¿ cÃ¡c instance bá»‹ lá»—i (health check failed). CÃ¡c Instance nÃ y Ä‘Æ°á»£c táº¡o má»›i vÃ  xoÃ¡ bá» 1 cÃ¡ch tá»± Ä‘á»™ng, nÃªn cáº§n cÃ³ ELB Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng traffic vÃ o chÃºng.\n3. Thiáº¿t káº¿ há»‡ thá»‘ng máº¡ng cho app. Äá»ƒ Ä‘áº£m báº£o an toÃ n, kiáº¿n trÃºc Ä‘Æ°á»£c Ä‘áº·t trong VPC, tÃ¡ch lÃ m 2 AZ. Báº¡n cÃ³ thá»ƒ tháº¥y 2 AZ (us-east-1c vÃ  us-east-1d) giá»‘ng há»‡t nhau. ÄÃ¢y lÃ  Ä‘á»ƒ cho há»‡ thá»‘ng váº«n hoáº¡t Ä‘á»™ng dÃ¹ AZ bá»‹ sáº­p. CÃ³ tá»•ng cá»™ng 4 subnet trong VPC, 2 public vÃ  2 private. á» 1 trong 2 public subnet, mÃ¬nh Ä‘Ã£ Ä‘á»ƒ 1 Ec2 vá»›i má»¥c Ä‘Ã­ch lÃ m Bastion Host.\nBastion Host lÃ  cÃ¡ch báº£o vá»‡ há»‡ thá»‘ng tá»‘t hÆ¡n báº±ng viá»‡c Ä‘áº·t resource trong private subnet, vÃ  truy cáº­p tá»« ngoÃ i sáº½ pháº£i Ä‘i qua Bastion Host Ä‘á»ƒ vÃ o Ä‘áº¿n bÃªn trong (truy cáº­p SSH, cÃ²n láº¡i náº¿u dÃ¹ng DNS cá»§a ALB thÃ¬ Ä‘i qua ALB).\n2 Private subnet cÃ²n láº¡i, mÃ¬nh Ä‘áº·t ASG. ASG sáº½ tá»± Ä‘á»™ng táº¡o cÃ¡c Ec2 instance trong 2 private subnet nÃ y vÃ  Ä‘iá»u hÆ°á»›ng request cá»§a mÃ¬nh tá»« ngoÃ i vÃ o Ä‘Ã³.\n"
},
{
	"uri": "/vi/6-cdk/6.2-runtask/",
	"title": "Thiáº¿t káº¿ AWS Batch",
	"tags": [],
	"description": "",
	"content": "Trong pháº§n trÆ°á»›c, sau khi thiáº¿t káº¿ xong CI/CD pipeline thÃ¬ mÃ¬nh Ä‘Ã£ tiáº¿p tá»¥c vá»›i AWS Batch. Trong pháº§n nÃ y, mÃ¬nh sáº½ Ä‘i qua tá»«ng bÆ°á»›c Ä‘á»ƒ thiáº¿t káº¿ AWS Batch báº±ng CDK, bao gá»“m\nTáº¡o role cho Batch. Trong AWS Batch console cÃ³ 1 khung lÃ  Execution role. MÃ¬nh cáº§n táº¡o vÃ  gÃ¡n role nÃ y cho Batch Thiáº¿t káº¿ háº¡ táº§ng máº¡ng VPC cho Batch Táº¡o Security Group cho Batch Táº¡o cÃ¡c components cÃ²n láº¡i cho Batch: Compute Env, Job Definition, Job Queue,\u0026hellip; Táº¡o EventBridge Ä‘á»ƒ cÃ³ thá»ƒ Schedule cho Batch cháº¡y theo lá»‹ch trÃ¬nh Náº¿u báº¡n tháº¯c máº¯c táº¡i sao khÃ´ng cÃ³ Bucket. ThÃ¬ trong workshop nÃ y mÃ¬nh Ä‘Ã£ táº¡o bucket thá»§ cÃ´ng. LÃ½ do lÃ  vÃ¬ viá»‡c pass tÃªn bucket vÃ o script crawler khÃ¡ khÃ³ khÄƒn do cÃ¡ch mÃ¬nh viáº¿t script. Do Ä‘Ã³ mÃ¬nh sáº½ pháº£i táº¡o 1 Bucket, pass tÃªn bucket vÃ o script crawler, sau Ä‘Ã³ má»›i cÃ³ thá»ƒ cháº¡y crawler.\nfrom aws_cdk import ( # Duration, Stack, # iam aws_iam as iam, # aws batch aws_batch as batch, # lambda aws_lambda as aws_lambda, # Duration Duration, # aws events aws_events as events, # aws events targets aws_events_targets as targets, # aws ec2 (for vpc) aws_ec2 as ec2, ) from constructs import Construct # Other lib import os # load the environment variables from dotenv import load_dotenv load_dotenv() # load ECR_REPO_NAME = os.getenv(\u0026#34;ECR_REPO\u0026#34;) JOB_DEFINITION_NAME = os.getenv(\u0026#34;JOB_DEFINITION\u0026#34;) JOB_QUEUE_NAME = os.getenv(\u0026#34;JOB_QUEUE\u0026#34;) JOB_NAME = os.getenv(\u0026#34;JOB_NAME\u0026#34;) JOB_ROLE_NAME = os.getenv(\u0026#34;ECS_ROLE_NAME\u0026#34;) BATCH_VPC_NAME = os.getenv(\u0026#34;BATCH_VPC_NAME\u0026#34;) BATCH_SUBNET_NAME = os.getenv(\u0026#34;BATCH_SUBNET_NAME\u0026#34;) BATCH_SG_NAME = os.getenv(\u0026#34;BATCH_SG_NAME\u0026#34;) class RunTaskStack(Stack): def __init__(self, scope: Construct, construct_id: str, **kwargs) -\u0026gt; None: super().__init__(scope, construct_id, **kwargs) # aws batch # For the simplicity of this, let create a role for ECS job ecs_role = iam.Role( scope=self, id=f\u0026#34;{JOB_ROLE_NAME}\u0026#34;, assumed_by=iam.ServicePrincipal(\u0026#39;ecs-tasks.amazonaws.com\u0026#39;), role_name=f\u0026#39;{JOB_ROLE_NAME}\u0026#39;, managed_policies=[ iam.ManagedPolicy.from_aws_managed_policy_name(\u0026#39;service-role/AmazonECSTaskExecutionRolePolicy\u0026#39;), # add full access to S3 iam.ManagedPolicy.from_aws_managed_policy_name(\u0026#39;AmazonS3FullAccess\u0026#39;), # add full access to ECR iam.ManagedPolicy.from_aws_managed_policy_name(\u0026#39;AmazonEC2ContainerRegistryFullAccess\u0026#39;), ], ) # +++ Create a VPC for the Batch +++ vpc = ec2.Vpc( scope=self, id = f\u0026#34;{BATCH_VPC_NAME}\u0026#34;, vpc_name=f\u0026#34;{BATCH_VPC_NAME}\u0026#34;, # set the max azs to 1 max_azs=1, # set the cidr cidr=\u0026#39;10.0.0.0/16\u0026#39;, # set the subnet configuration subnet_configuration=[ ec2.SubnetConfiguration( name=f\u0026#34;{BATCH_SUBNET_NAME}\u0026#34;, subnet_type=ec2.SubnetType.PUBLIC, cidr_mask=24, ), ], ) # Create a Security Group for the Batch in the VPC batch_security_group = ec2.SecurityGroup( scope=self, id=f\u0026#34;BatchSecurityGroup\u0026#34;, vpc=vpc, security_group_name=f\u0026#34;{BATCH_SG_NAME}\u0026#34;, # allow all outbound traffic allow_all_outbound=True, ) # create compute environment compute_environment = batch.CfnComputeEnvironment( scope=self, id=\u0026#34;JobScrapingComputeEnvironment\u0026#34;, compute_environment_name=\u0026#39;job-scraping-compute-environment\u0026#39;, # if you set the type as MANAGED, it will pass in the the settings from Launch Template, otherwise you need to set the settings manually type=\u0026#39;MANAGED\u0026#39;, state=\u0026#39;ENABLED\u0026#39;, # Compute Resources: to set the type of compute resource compute_resources=batch.CfnComputeEnvironment.ComputeResourcesProperty( maxv_cpus=4, subnets=[vpc.public_subnets[0].subnet_id], type=\u0026#39;FARGATE_SPOT\u0026#39;, # Security Group security_group_ids=[batch_security_group.security_group_id], ), # Service Role Not neccessary # service_role=batch_role.role_arn, ) # create job queue job_queue = batch.CfnJobQueue( scope=self, id=f\u0026#34;{JOB_QUEUE_NAME}\u0026#34;, job_queue_name=f\u0026#39;{JOB_QUEUE_NAME}\u0026#39;, priority=1, state=\u0026#39;ENABLED\u0026#39;, compute_environment_order=[ batch.CfnJobQueue.ComputeEnvironmentOrderProperty( compute_environment=compute_environment.ref, order=1, ) ], ) # create job definition job_definition = batch.CfnJobDefinition( scope=self, id=f\u0026#34;{JOB_DEFINITION_NAME}\u0026#34;, job_definition_name=f\u0026#39;{JOB_DEFINITION_NAME}\u0026#39;, timeout={ \u0026#39;attemptDurationSeconds\u0026#39;: 900, }, # type (so this is not multi-node) type=\u0026#39;container\u0026#39;, platform_capabilities=[\u0026#39;FARGATE\u0026#39;], # container properties container_properties=batch.CfnJobDefinition.ContainerPropertiesProperty( # THIS IS \u0026#34;SOME\u0026#34; OF THE FARGATE PLATFORM CONFIGURATION. THE REASON I SAID SOME IS BECAUSE, NOT SURE WHY, THE SETTINGS ARE IN MANY PLACES # assign public IP (does not found) # Ephemeral storage ephemeral_storage=batch.CfnJobDefinition.EphemeralStorageProperty( size_in_gib=30 # between 21 and 200 ), # Execution role execution_role_arn=ecs_role.role_arn, # ++++ THIS IS SOME MORE FARGATE CONFIGURATION +++++ # This is the Latest that you see in the console fargate_platform_configuration= batch.CfnJobDefinition.FargatePlatformConfigurationProperty( platform_version=\u0026#39;LATEST\u0026#39;, ), # network configuration (For public IP) network_configuration=batch.CfnJobDefinition.NetworkConfigurationProperty( assign_public_ip=\u0026#39;ENABLED\u0026#39;, ), # privileged: Do not add this!!! Fargate actually ban this # privileged=True, # THIS IS ON THE TAB CONTAINER CONFIGURATION IN JOB DEFINITION (Step 2 if you use Console) # This is the link to the ECR that we store our image (the image that we build, and create in the CICD step). Don\u0026#39;t forget to add the tag image=f\u0026#39;{ECR_REPO_NAME}:latest\u0026#39;, # Honestly, this is not really useful, since I have already set the ENTRYPOINT in the Dockerfile command=[ \u0026#39;echo\u0026#39;, \u0026#39;Job Definition Initiated\u0026#39;, ], # job role: Explain simply, Job role is more specific than Execution role. All the job can have the same execution role, but different job role job_role_arn=ecs_role.role_arn, # memory and vcpus resource_requirements=[ batch.CfnJobDefinition.ResourceRequirementProperty( type=\u0026#39;MEMORY\u0026#39;, value=\u0026#39;2048\u0026#39;, ), batch.CfnJobDefinition.ResourceRequirementProperty( type=\u0026#39;VCPU\u0026#39;, value=\u0026#39;1\u0026#39;, ), ], ), ) # +++ Create a Lambda to submit job to Batch +++ # create a role for lambda to submit job to batch submit_job_lambda_role = iam.Role( scope=self, id=\u0026#34;SubmitBatchJobLambdaRole\u0026#34;, role_name=\u0026#34;SubmitJobLambdaRole\u0026#34;, assumed_by=iam.ServicePrincipal(\u0026#34;lambda.amazonaws.com\u0026#34;), # add the job submit policy to the role managed_policies=[ iam.ManagedPolicy.from_aws_managed_policy_name( managed_policy_name=\u0026#34;service-role/AWSBatchServiceEventTargetRole\u0026#34; ), ], ) # create a lambda function submit_job_lambda = aws_lambda.Function( scope=self, id=\u0026#34;SubmitJobLambda\u0026#34;, function_name=\u0026#34;CDK-JobScraping-Submit-Job-Batch\u0026#34;, runtime=aws_lambda.Runtime.PYTHON_3_9, code=aws_lambda.Code.from_asset(\u0026#34;workshop1/lambda_functions/TriggerJobScrapingTask/\u0026#34;), handler=\u0026#34;lambda_function.lambda_handler\u0026#34;, timeout=Duration.seconds(60), # pass in the role role=submit_job_lambda_role, environment={ \u0026#34;JOB_NAME\u0026#34;: JOB_NAME, \u0026#34;JOB_QUEUE\u0026#34;: JOB_QUEUE_NAME, \u0026#34;JOB_DEFINITION\u0026#34;: JOB_DEFINITION_NAME, }, ) # +++ Event Bridge Rule +++ # create a rule to trigger the lambda function at 6am everyday rule = events.Rule( scope=self, id=\u0026#34;TriggerSubmitJobLambda\u0026#34;, rule_name=\u0026#34;TriggerSubmitJobLambda\u0026#34;, schedule=events.Schedule.cron( minute=\u0026#34;0\u0026#34;, hour=\u0026#34;6\u0026#34;, ), ) # add the lambda function as the target rule.add_target(targets.LambdaFunction(submit_job_lambda)) "
},
{
	"uri": "/vi/4-result/",
	"title": "Káº¿t quáº£",
	"tags": [],
	"description": "",
	"content": "Káº¿t quáº£ ChÃºc má»«ng báº¡n. Váº­y lÃ  báº¡n Ä‘Ã£ Ä‘áº¿n Ä‘Æ°á»£c bÆ°á»›c cuá»‘i cÃ¹ng rá»“i. Viá»‡c cÃ²n láº¡i lÃ  táº­n hÆ°á»Ÿng thÃ nh quáº£ thÃ´i\nVÃ o láº¡i Ec2, chá»n Load Balancer. Copy DNS name tá»« Load Balancer vá»«a táº¡o NÃ³ sáº½ trÃ´ng nhÆ° tháº¿ nÃ y CDKJobScrapingFrontendLB-1591468448.us-east-1.elb.amazonaws.com ThÃªm cá»•ng 8501 vÃ o phÃ­a sau CDKJobScrapingFrontendLB-1591468448.us-east-1.elb.amazonaws.com:8501\nNáº¿u báº¡n ra Ä‘Æ°á»£c trang nhÆ° tháº¿ nÃ y thÃ¬ chÃºc má»«ng báº¡n Ä‘Ã£ thÃ nh cÃ´ng "
},
{
	"uri": "/vi/6-cdk/6.3-wrapup/",
	"title": "Thiáº¿t káº¿ frontend Webapp",
	"tags": [],
	"description": "",
	"content": "Theo mÃ¬nh thÃ¬ Ä‘Ã¢y lÃ  pháº§n khÃ³ nháº¥t trong cáº£ 3 pháº§n khi lÃ m báº±ng CDK. LÃ½ do lÃ  vÃ¬ pháº§n nÃ y ráº¥t dÃ i. Sau Ä‘Ã¢y lÃ  tá»•ng quan vá» nhá»¯ng gÃ¬ mÃ¬nh sáº½ lÃ m trong pháº§n nÃ y:\nThiáº¿t káº¿ háº¡ táº§ng máº¡ng Äoáº¡n code dÆ°á»›i táº¡o 1 VPC vá»›i 2 subnet, 1 public vÃ  1 private. Khi táº¡o Public Subnet báº±ng code thÃ¬ AWS tá»± route tá»›i Internet Gateway cho mÃ¬nh. VÃ  khi táº¡o Private Subnet loáº¡i PRIVATE_WITH_NAT thÃ¬ AWS tá»± táº¡o NAT Gateway cho mÃ¬nh.\n# Create VPC vpc = ec2.Vpc( scope=self, id=\u0026#39;CDKJobScrapingFrontend\u0026#39;, vpc_name=f\u0026#39;{VPC_NAME}\u0026#39;, # set the CIDR for the VPC cidr= \u0026#39;10.0.0.0/16\u0026#39;, # enable DNS support enable_dns_support=True, # setup 2 subnet subnet_configuration=[ # public subnet ec2.SubnetConfiguration( name=\u0026#34;CDKJobScrapingFrontendPublic\u0026#34;, subnet_type=ec2.SubnetType.PUBLIC, cidr_mask=24, ), # private subnet with NAT ec2.SubnetConfiguration( name=\u0026#34;CDKJobScrapingFrontendPrivate\u0026#34;, subnet_type=ec2.SubnetType.PRIVATE_WITH_NAT, cidr_mask=24, ), ], ) Táº¡o Security Group cho EC2 Instance vÃ  Bastion Host # +++ Create Ec2 +++ # create a security group for the ec2 private instance private_ec2_security_group = ec2.SecurityGroup( scope=self, id=\u0026#34;CDKJobScrapingFrontendSecurityGroup\u0026#34;, vpc=vpc, allow_all_outbound=True, description=\u0026#34;Security Group for the EC2 private instance\u0026#34;, security_group_name=\u0026#34;CDK-JobScraping-Frontend-Private-SG\u0026#34;, ) # add the ingress rule to the security group, open custom TPC port 8501 private_ec2_security_group.add_ingress_rule( peer=ec2.Peer.any_ipv4(), connection=ec2.Port.tcp(8501), description=\u0026#34;Allow inbound traffic from anywhere for port 8501\u0026#34;, ) # add ssh port 22 for for SG for the EC2 private instance private_ec2_security_group.add_ingress_rule( peer=ec2.Peer.any_ipv4(), connection=ec2.Port.tcp(22), description=\u0026#34;Allow inbound traffic from anywhere for port 22\u0026#34;, ) # create security group for bastion host bastion_security_group = ec2.SecurityGroup( scope=self, id=\u0026#34;CDKJobScrapingFrontendBastionSecurityGroup\u0026#34;, vpc=vpc, allow_all_outbound=True, description=\u0026#34;Security Group for the bastion host\u0026#34;, security_group_name=\u0026#34;CDK-JobScraping-Frontend-Bastion-SG\u0026#34;, ) # add the ingress rule to the security group, open SSH port 22 bastion_security_group.add_ingress_rule( peer=ec2.Peer.any_ipv4(), connection=ec2.Port.tcp(22), description=\u0026#34;Allow inbound traffic from anywhere for port 22\u0026#34;, ) Táº¡o Bastion Host LÆ°u Ã½: do mÃ¬nh khÃ´ng tÃ¬m Ä‘Æ°á»£c cÃ¡ch download key pem khi dÃ¹ng CDK, nÃªn báº¡n sáº½ pháº£i táº¡o sáºµn 1 key pem vÃ  lÆ°u tÃªn vÃ o biáº¿n mÃ´i trÆ°á»ng nhÃ©.\n# create a bastion host # AMI for bastion host ami_bastion_host = ec2.MachineImage.generic_linux( { \u0026#34;us-east-1\u0026#34;:\u0026#34;ami-053b0d53c279acc90\u0026#34; } ) # DON\u0026#39;T FORGET THAT YOU WILL NEED TO CREATE A KEY PAIR IN THE AWS CONSOLE (BECAUSE YOU COULDN\u0026#39;T ACCESS IT LATTER IF CREATE HERE) bastion_host = ec2.Instance( scope=self, id=\u0026#34;CDKJobScrapingFrontendBastionHost\u0026#34;, instance_type=ec2.InstanceType(\u0026#34;t2.micro\u0026#34;), machine_image=ec2.MachineImage.latest_amazon_linux( generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2 ), vpc=vpc, vpc_subnets=ec2.SubnetSelection( subnet_type=ec2.SubnetType.PUBLIC ), security_group=bastion_security_group, key_name=f\u0026#39;{KEY_NAME}\u0026#39;, instance_name=\u0026#39;CDKJobScrapingFrontendBastionHost\u0026#39;, ) Táº¡o ASG vÃ  ALB Trong Ä‘oáº¡n code dÆ°á»›i, mÃ¬nh Ä‘Ã£:\nTáº¡o 1 role cho ASG Táº¡o Launch Instance. Cáº§n gÃ¡n key pem náº¿u nhÆ° muá»‘n truy cáº­p vÃ o instance sau nÃ y. Launch Instance cÅ©ng cáº§n SG. Äá»“ng thá»i cáº§n gÃ¡n User Data cho Launch template Táº¡o ASG Táº¡o ALP Táº¡o Target Group vÃ  gÃ¡n ASG vÃ o Target Group # +++ Create Load Balancer and Auto Scaling Group +++ # But first, we will need 2 things # 1. Create an AMI that have all the packages installed # 3. Create a Role for ASG # Since the first steps would be done in console, I\u0026#39;ll do the 3rd step here # Create a role for ASG role = iam.Role( scope=self, id=\u0026#39;CDKJobScrapingFrontendRole\u0026#39;, assumed_by=iam.ServicePrincipal(\u0026#39;ec2.amazonaws.com\u0026#39;), role_name=\u0026#39;CDKJobScrapingFrontendRole\u0026#39;, managed_policies=[ # Read access to Ec2 iam.ManagedPolicy.from_aws_managed_policy_name(\u0026#39;AmazonEC2ReadOnlyAccess\u0026#39;), # Full access to S3 iam.ManagedPolicy.from_aws_managed_policy_name(\u0026#39;AmazonS3FullAccess\u0026#39;), ] ) # Okay, now let move on to create the Load Balancer and Auto Scaling Group # Create Launch Template. Don\u0026#39;t Forget a Key Pair launch_template = ec2.LaunchTemplate( scope=self, id=\u0026#39;CDKJobScrapingFrontendLaunchTemplate\u0026#39;, launch_template_name=\u0026#39;CDKJobScrapingFrontendLaunchTemplate\u0026#39;, # set the machine image from the AMI that we created machine_image=ec2.MachineImage.generic_linux( { \u0026#34;us-east-1\u0026#34;:f\u0026#39;{AMI}\u0026#39; } ), # set the instance type instance_type=ec2.InstanceType(\u0026#34;t2.micro\u0026#34;), # set the key pair key_name=f\u0026#39;{KEY_NAME}\u0026#39;, # set the security group security_group=private_ec2_security_group, # set the role role=role, # set the block device mapping: use AMI block device mapping user_data=ec2.UserData.custom( \u0026#39;\u0026#39;\u0026#39;Content-Type: multipart/mixed; boundary=\u0026#34;//\u0026#34; MIME-Version: 1.0 --// Content-Type: text/cloud-config; charset=\u0026#34;us-ascii\u0026#34; MIME-Version: 1.0 Content-Transfer-Encoding: 7bit Content-Disposition: attachment; filename=\u0026#34;cloud-config.txt\u0026#34; #cloud-config cloud_final_modules: - [scripts-user, always] --// Content-Type: text/x-shellscript; charset=\u0026#34;us-ascii\u0026#34; MIME-Version: 1.0 Content-Transfer-Encoding: 7bit Content-Disposition: attachment; filename=\u0026#34;userdata.txt\u0026#34; #!/bin/bash # Run the app.py script cd /home/ubuntu/ sudo streamlit run streamlit-app.py \u0026gt; output.txt 2\u0026gt;\u0026amp;1 --//--\u0026#39;\u0026#39;\u0026#39; ), ) # Create Auto Scaling Group auto_scaling_group = autoscaling.AutoScalingGroup( scope=self, vpc=vpc, id=\u0026#39;CDKJobScrapingFrontendAutoScalingGroup\u0026#39;, # set the name for the Auto Scaling Group auto_scaling_group_name=\u0026#39;CDKJobScrapingFrontendAutoScalingGroup\u0026#39;, # set launch template launch_template = launch_template, # VPC private subnet vpc_subnets=ec2.SubnetSelection( subnet_type=ec2.SubnetType.PRIVATE_WITH_NAT # current we since we only have 2 private sbunet, so can use this to select all ), # set the min, max, and desired capacity min_capacity=0, max_capacity=2, desired_capacity=1, ) # create a load balancer load_balancer = elbv2.ApplicationLoadBalancer( scope=self, id=\u0026#39;CDKJobScrapingFrontendLoadBalancer\u0026#39;, vpc=vpc, internet_facing=True, load_balancer_name=\u0026#39;CDKJobScrapingFrontendLB\u0026#39;, security_group=private_ec2_security_group, ) # create a target group that target to the Auto Scaling Group target_group = elbv2.ApplicationTargetGroup( scope=self, id=\u0026#39;CDKJobScrapingFrontendTargetGroup\u0026#39;, vpc=vpc, port=8501, protocol=elbv2.ApplicationProtocol.HTTP, targets=[auto_scaling_group], target_group_name=\u0026#39;CDKJobScrapingFrontendTG\u0026#39;, ) # create a listener that listen to the target group listener = load_balancer.add_listener( id=\u0026#39;CDKJobScrapingFrontendListener\u0026#39;, port=8501, protocol=elbv2.ApplicationProtocol.HTTP, open=True, default_target_groups=[target_group], ) "
},
{
	"uri": "/vi/5-cleanup/",
	"title": "Dá»n dáº¹p tÃ i nguyÃªn",
	"tags": [],
	"description": "",
	"content": "Giá»›i thiá»‡u tá»•ng quÃ¡t Sau khi hoÃ n thÃ nh workshop. Báº¡n cáº§n xoÃ¡ Ä‘i tÃ i nguyÃªn Ä‘á»ƒ trÃ¡nh phÃ¡t sinh thÃªm chi phÃ­.\nXoÃ¡ ASG VÃ o láº¡i Ec2, chá»n Auto Scaling Groups Chá»n ASG báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Action -\u0026gt; Delete. Nháº­p chá»¯ delete Ä‘á»ƒ xÃ¡c nháº­n XoÃ¡ Load Balancer VÃ o láº¡i EC2, chá»n Load Balancers (trÃªn Auto Scaling Groups 1 xÃ­u, ngay trÃªn target groups) Chá»n Load Balancer báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Action -\u0026gt; Delete Load Balancer. GÃµ confirm -\u0026gt; Delete XoÃ¡ Target Group VÃ o láº¡i EC2, chá»n Target Groups (trÃªn Auto Scaling Groups) Chá»n Target Group báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Action -\u0026gt; Delete. Chá»n Yes, delete XoÃ¡ nhá»¯ng Instane VÃ o Ec2, chá»n Instances Chá»n nhá»¯ng instance Ä‘ang cháº¡y vÃ  chá»n Instance state -\u0026gt; Terminate. XoÃ¡ AWS Batch Job Definition VÃ o AWS Batch, chá»n tab Job definitions Chá»n Job Definition báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Deregister XoÃ¡ AWS Batch Job Queue VÃ o AWS Batch, chá»n tab Job queues Chá»n Job Queue báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Disable Sau khi disable, chá»n láº¡i queue vÃ  chá»n Delete XoÃ¡ AWS Batch Compute Environment VÃ o AWS Batch, chá»n tab Compute environments Chá»n Compute Environment báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Disable Chá»n láº¡i Compute Environment vÃ  chá»n Delete (pháº£i Ä‘á»£i 1 lÃºc cho Ä‘áº¿n khi job queue xoÃ¡ xong thÃ¬ má»›i xoÃ¡ Ä‘Æ°á»£c compute environment) XoÃ¡ Codebuild Project VÃ o AWS Codebuild Chá»n Project báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Delete build project Nháº­p delete Ä‘á»ƒ confirm, chá»n Delete XoÃ¡ AWS ECR Repository VÃ o AWS ECR Chá»n Repository báº¡n Ä‘Ã£ táº¡o vÃ  chá»n Delete Nháº­p delete Ä‘á»ƒ confirm, chá»n Delete XoÃ¡ VPC VÃ o VPC Chá»n nhá»¯ng VPC báº¡n Ä‘Ã£ táº¡o, Chá»n Action -\u0026gt; Delete VPC Nháº­p delete Ä‘á»ƒ confirm, chá»n Delete "
},
{
	"uri": "/vi/6-cdk/6.3-frontend/",
	"title": "HoÃ n táº¥t, Cháº¡y CDK vÃ  Dá»n dep",
	"tags": [],
	"description": "",
	"content": "Váº­y lÃ  báº¡n hoÃ n thÃ nh Ä‘Æ°á»£c pháº§n bonus cá»§a workshop nÃ y rá»“i. Sau khi hiá»ƒu cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n vÃ  cÃ¡c hoáº¡t Ä‘á»™ng cá»§a tá»«ng file. Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u táº¡o há»‡ thá»‘ng báº±ng CDK rá»“i.\n1. Äáº£m báº£o ráº±ng báº¡n Ä‘Ã£ chuáº©n bá»‹ Ä‘áº§y Ä‘á»§ HÃ£y vÃ o file .env vÃ  thay Ä‘á»•i tuá»³ vÃ o mÃ´i trÆ°á»ng cá»§a báº¡n. ÄÃ¢y thÆ°á»ng lÃ  nhá»¯ng tÃ i nguyÃªn mÃ¬nh khÃ´ng táº¡o báº±ng CDK Ä‘Æ°á»£c. HÃ£y cháº¯c ráº±ng mÃ¬nh Ä‘Ã£ login vÃ o AWS vÃ  vÃ o tÃ i khoáº£n github chá»©a code crawler cá»§a báº¡n 2. Cháº¡y CDK Báº¡n cÃ³ thá»ƒ cháº¡y lá»‡nh sau trong IDE Ä‘á»ƒ vÃ o mÃ´i trÆ°á»ng CDK source .venv/bin/activate Sau khi vÃ o mÃ´i trÆ°á»ng CDK, báº¡n cÃ³ thá»ƒ cháº¡y lá»‡nh sau Ä‘á»ƒ cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t $ pip install -r requirements.txt Sau Ä‘Ã³, báº¡n cÃ³ thá»ƒ synth ra cÃ¡c file Cloudformation báº±ng lá»‡nh sau: cdk synth Náº¿u nhÆ° Ä‘Æ°á»£c yÃªu cáº§u bootstrap, báº¡n cÃ³ thá»ƒ cháº¡y lá»‡nh sau: cdk bootstrap Cuá»‘i cÃ¹ng lÃ  deploy lÃªn báº±ng lá»‡nh sau: cdk deploy --all Ä‘á»ƒ cháº¡y táº¥t cáº£ stack 3. Dá»n dáº¹p Sau khi cháº¡y xong, náº¿u muá»‘n xoÃ¡ táº¥t cáº£ cÃ¡c tÃ i nguyÃªn, báº¡n cÃ³ thá»ƒ cháº¡y lá»‡nh sau: cdk destroy --all, Nhanh hÆ¡n ráº¥t nhiá»u so vá»›i thá»§ cÃ´ng Ä‘Ãºng khÃ´ng\n"
},
{
	"uri": "/vi/6-cdk/",
	"title": "XÃ¢y dá»±ng workshop báº±ng CDK",
	"tags": [],
	"description": "",
	"content": "Giá»›i thiá»‡u tá»•ng quÃ¡t ÄÃ¢y lÃ  pháº§n bonus cá»§a workshop nÃ y. Báº¡n sáº½ Ä‘Æ°á»£c hÆ°á»›ng dáº«n xÃ¢y dá»±ng láº¡i workshop nÃ y báº±ng CDK.\nSÆ¡ lÆ°á»£c vá» CDK: ÄÃ¢y lÃ  1 dá»‹ch vá»¥ cá»§a AWS, cho phÃ©p xÃ¢y dá»±ng vÃ  triá»ƒn khai cÃ¡c tÃ i nguyÃªn AWS báº±ng code. CDK há»— trá»£ nhiá»u ngÃ´n ngá»¯ nhÆ° Python, Javascript, Typescript, Java, C#,\u0026hellip; Trong bÃ i workshop nÃ y thÃ¬ mÃ¬nh sáº½ dÃ¹ng CDK vá»›i Python. CDK táº¡o cÃ¡c stack trong Cloudformation Ä‘á»ƒ triá»ƒn khai tÃ i nguyÃªn. NÃªn náº¿u gáº·p lá»—i hay cáº§n giÃ¡m sÃ¡t, báº¡n cÃ³ thá»ƒ vÃ o AWS Cloudformation.\nChuáº©n bá»‹ Äáº§u tiÃªn, báº¡n cáº§n clone github repo chá»©a code CDK vá». Báº¡n cÃ³ thá»ƒ dÃ¹ng lá»‡nh sau: git clone -b cdk https://github.com/MinhThieu145/FCJBootcamp.git Sau Ä‘Ã³, báº¡n cáº§n setup AWS CLI Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i Resource. Náº¿u báº¡n sá»­ dá»¥ng pip thÃ¬ cÃ³ thá»ƒ sá»­ dá»¥ng lá»‡nh sau Ä‘á»ƒ install AWS CLI: pip install awscli. Äá»ƒ kiá»ƒm tra thÃ¬ báº¡n cÃ³ thá»ƒ dÃ¹ng lá»‡nh: aws --version\nSau Ä‘Ã³, báº¡n cáº§n Ä‘Äƒng nháº­p vÃ o tÃ i khoáº£n AWS cá»§a mÃ¬nh. Báº¡n cÃ³ thá»ƒ dÃ¹ng lá»‡nh sau: aws configure. Lá»‡nh nÃ y sáº½ yÃªu cáº§u báº¡n nháº­p Access Key vÃ  Secret Key. Báº¡n cÃ³ thá»ƒ láº¥y 2 key nÃ y á»Ÿ pháº§n IAM trÃªn AWS Console.\nVÃ o AWS IAM, chá»n User vÃ  chá»n Add User\nChá»n User name -\u0026gt; Next\nTrong tab Permission, chá»n Attach policies directly -\u0026gt; TÃ¬m vÃ  chá»n AdministratorAccess -\u0026gt; Next\nChá»n Create user\nVÃ o láº¡i IAM -\u0026gt; User vÃ  chá»n user báº¡n vá»«a táº¡o. Chá»n vÃ o tab Security Credential KÃ©o xuá»‘ng pháº§n Access Key vÃ  chá»n Create access key\nChá»n Use case lÃ  Command Line Interface (CLI) -\u0026gt; Tick confirmation -\u0026gt; Next\nChá»n Create access key\nBÃªn cáº¡nh nÃºt Done chá»n Download .csv. File nÃ y sáº½ chá»©a Access Key vÃ  Secret Key cá»§a báº¡n. Báº¡n cÅ©ng cÃ³ thá»ƒ copy trá»±c tiáº¿p Access Key vÃ  Secret access key tá»« console VÃ o láº¡i IDE cá»§a báº¡n, má»Ÿ terminal lÃªn vÃ  cháº¡y lá»‡nh aws configure. Náº¿u Ä‘Ã£ cÃ i CLI thÃ¬ sáº½ cÃ³ prompt há»i access key vÃ  Secret access key. Paste vÃ o lÃ  xong. Báº¡n cÅ©ng cÃ³ thá»ƒ chá»n region Ä‘Ãºng vá»›i region Ä‘ang sá»­ dá»¥ng Váº­y lÃ  báº¡n Ä‘Ã£ hoÃ n thÃ nh viá»‡c Ä‘ang nháº­p vÃ o tÃ i khoáº£n AWS cá»§a mÃ¬nh. BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y CDK Ä‘Æ°á»£c rá»“i.\n"
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]