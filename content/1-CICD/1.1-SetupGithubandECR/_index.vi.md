---
title : "Chu·∫©n b·ªã Github Repo "
date :  "`r Sys.Date()`" 
weight : 1 
chapter : false
pre : " <b> 1.1 </b> "
---

Trong b√†i n√†y, c√°c b·∫°n s·∫Ω chu·∫©n b·ªã c√°c files c·∫ßn thi·∫øt cho c√°c b√†i sau. M√¨nh s·∫Ω ƒëi qua t·ª´ng ph·∫ßn. Trong b√†i lab n√†y, m√¨nh s·∫Ω s·ª≠ d·ª•ng VSCode ƒë·ªÉ chu·∫©n b·ªã ƒë·∫ßy ƒë·ªß c√°c file ·ªü m√¥i tr∆∞·ªùng local v√† ƒë·∫©y l√™n Github. M√¨nh c≈©ng s·ª≠ d√πng Console ƒë·ªÉ deploy ki·∫øn tr√∫c l√™n cloud. ·ªû ph·∫ßn 2 c·ªßa b√†i workshop, m√¨nh s·∫Ω ch·ªâ c√°ch c√°c b·∫°n c√≥ th·ªÉ deploy l√™n b·∫±ng CDK (Cloud Development Kit) n·∫øu b·∫°n mu·ªën h·ªçc th√™m v·ªÅ IaC.

## Chu·∫©n b·ªã crawler v√† push l√™n Github
Tr∆∞·ªõc h·∫øt, b·∫°n c·∫ßn chu·∫©n b·ªã c√°c file crawler v√† ƒë·∫©y l√™n Github. ƒê√¢y s·∫Ω l√† crawler m√† ch√∫ng ta s·∫Ω deploy l√™n cloud. B·∫°n h√£y v√†o link Github sau: [Github Crawler](https://github.com/MinhThieu145/Job-Scraper-Home.git). Sau khi v√†o r·ªìi h√£y clone repo n√†y v·ªÅ m√°y c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ clone b·∫±ng c√°ch ch·∫°y l·ªánh sau:

```
git clone -b indeed-scraper https://github.com/MinhThieu145/Job-Scraper-Home.git
```

N·∫øu nh∆∞ b·∫°n b·ªã l·ªói ·ªü c√¢u l·ªánh tr√™n, h√£y th·ª≠ d√πng:

```
git --version
```
N·∫øu nh∆∞ b·∫°n th·∫•y k·∫øt qu·∫£ tr·∫£ v·ªÅ hi·ªÉn th·ªã r√µ git version. Th√¨ b·∫°n ƒë√£ c√†i git th√†nh c√¥ng. N·∫øu kh√¥ng, b·∫°n c·∫ßn c√†i git tr∆∞·ªõc khi clone repo. B·∫°n c√≥ th·ªÉ c√†i git b·∫±ng c√°ch tham kh·∫£o link sau [C√°ch c√†i Github cho VsCode](https://www.geeksforgeeks.org/how-to-install-git-in-vs-code/). Sau khi clone ho√†n t·∫•t, b·∫°n s·∫Ω c√≥ 1 repo nh∆∞ sau:

```markdown
üì¶Job-Scraper-Home
 ‚î£ üìÇ.git
 ‚î£ üìÇ__pycache__
 ‚î£ üìÇresult
 ‚î£ üìú.gitignore
 ‚î£ üìúbuildspec.yml
 ‚î£ üìúdockerfile
 ‚î£ üìúexploration.ipynb
 ‚î£ üìújob_description_analyzer.py
 ‚î£ üìúmain.py
 ‚î£ üìúrequirements.txt
 ‚îó üìúscraper.py
```

M√¨nh s·∫Ω ƒëi qua t·ª´ng file v√† folder m√† b·∫°n c·∫ßn bi·∫øt trong repo n√†y:

### 1. main.py v√† scraper.py
ƒê·∫ßu ti√™n l√† file **main.py**. File c√≥ nhi·ªám v·ª• ch·∫°y file scraper.py v√† ch·ª©a k·∫øt qu·∫£ trong 1 folder t√™n l√† result (s·∫Ω t·∫°o folder m·ªõi n·∫øu kh√¥ng t·ªìn t·∫°i). Sau c√πng, script s·∫Ω ƒë·∫©y t·∫•t c·∫£ files trong folder result l√™n S3.

```python
# import indeed scraper
import scraper

# import analyze data function
import job_description_analyzer

# some other libraries
import os
import pandas as pd

# main function
def main():

    # clean the result folder
    # get current dir
    current_dir = os.getcwd()

    # get the result folder if exit
    try:
        # if the result folder exists
        result_dir = os.path.join(current_dir, 'result')
        # delete all the files in the result folder
        for file in os.listdir(result_dir):
            os.remove(os.path.join(result_dir, file))

        
    except:
        # create a new folder called result
        os.mkdir('result')
        result_dir = os.path.join(current_dir, 'result')


    # run the scraper
    scraper.main()

    # get the result from a folder called result

    # loop through the result folder
    for file in os.listdir(result_dir):
        # if that is a csv file
        if file.endswith('.csv'):
            # read with pandas
            df = pd.read_csv(os.path.join(result_dir, file))

            # if the dataframe is not empty
            if not df.empty:
                # pass that to the analyze data function
                job_description_analyzer.main(df=df, df_name=file.split('.')[0])
                    


if __name__ == "__main__":
    main()


```

 N·∫øu b·∫°n ƒë·ªçc kƒ© code, b·∫°n s·∫Ω th·∫•y main.py loop qua t·∫•t c·∫£ file ƒëu√¥i **.csv** trong folder result v√† g·ªçi 1 function kh√°c trong **job_description_analyzer.py** tr∆∞·ªõc khi ƒë·∫©y l√™n S3. L√Ω do l√† v√¨ m√¨nh ƒë√£ c·∫Øt ng·∫Øn repo ƒëi nhi·ªÅu. Ban ƒë·∫ßu crawler s·∫Ω c√≥ nhi·ªám v·ª• nh∆∞ sau.

- main.py s·∫Ω l√™n S3 ƒë·ªÉ t√¨m c√°c crawlers (m·ªói website l√† 1 crawler kh√°c nhau) v√† ch·∫°y c√°c crawler n√†y.
- C√°c crawler n√†y sau khi ch·∫°y xong ƒë·ªÅu s·∫Ω l∆∞u k·∫øt qu·∫£ v√†o folder result. - Sau ƒë√≥, file job_description_analyzer.py c√≥ nhi·ªám v·ª• extract nh·ªØng t·ª´ kho√° v√† nh·ªØng th√¥ng tin quan tr·ªçng b·∫±ng GPT API, tr∆∞·ªõc khi l∆∞u k·∫øt qu·∫£ l·∫°i
- Cu·ªëi c√πng, c·∫£ k·∫øt qu·∫£ scrap ban ƒë·∫ßu v√† sau khi x·ª≠ l√Ω ƒë∆∞·ª£c ƒë·∫©y l√™n S3. 

Do qu√° tr√¨nh n√†y kh√° l√¢u, d·ªÖ h·ªèng v√† kh√¥ng hi·ªáu qu·∫£ khi g·∫ßn nh∆∞ x·ª≠ l√Ω ho√†n to√†n b·∫±ng code. N·∫øu b·∫°n mu·ªën th·ª≠ l√†m l·∫°i, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng AWS Step Function v√† AWS SNS ƒë·ªÉ decouple c√°c ph·∫ßn, nh·∫±m ƒë·∫£m b·∫£o th·ª© t·ª± th·ª±c hi·ªán v√† ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa Pipeline. Nh∆∞ng trong b√†i lab n√†y m√¨nh s·∫Ω kh√¥ng ƒëi qua ph·∫ßn ƒë√≥

### 2. dockerfile v√† requirements.txt
ƒê√¢y l√† 2 files c·∫ßn thi·∫øt ƒë·ªÉ c√≥ th·ªÉ build 1 docker image t·ª´ code. Trong File **dockerfile**, m√¨nh ƒë√£

- S·ª≠ d·ª•ng based image l√† **Ubuntu:22.04**. Nh∆∞ng b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng nh·ªØng base image kh√°c, mi·ªÖn l√† c√≥ c√†i s·∫µn Python3. N·∫øu kh√¥ng b·∫°n s·∫Ω ph·∫£i t·ª± c√†i ƒë·∫∑t Python3
- C√†i ƒë·∫∑t v√† update pip ƒë·ªÉ t·∫£i c√†i c√°c package c·∫ßn thi·∫øt cho crawler. T√™n c·ªßa c√°c package n√†y ƒë∆∞·ª£c l∆∞u trong file **requirements.txt**. Trong b√†i lab n√†y, m√¨nh ƒë√£ s·ª≠ d·ª•ng boto3 ƒë·ªÉ c√≥ th·ªÉ g·ªçi c√°c API c·ªßa AWS, openai ƒë·ªÉ c√≥ th·ªÉ g·ªçi API c·ªßa GPT3 (c√≥ th·ªÉ b·ªè v√¨ kh√¥ng d√πng n·ªØa), pandas ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu, selenium ƒë·ªÉ c√≥ th·ªÉ ch·∫°y crawler v√† webdriver_manager ƒë·ªÉ c√≥ th·ªÉ t·ª± ƒë·ªông t·∫£i driver cho selenium. T·∫•t c·∫£ c√°c packages n√†y ƒë·ªÅu ƒë∆∞·ª£c l∆∞u trong file requirements.txt. B·∫°n c√≥ th·ªÉ th√™m b·ªõt c√°c packages n√†y t√πy theo √Ω mu·ªën.

```r
boto3==1.26.165
openai==0.27.7
pandas==1.5.3
selenium==4.10.0
tenacity==8.2.2
webdriver_manager==3.8.6
```
- C√†i ƒë·∫∑t Chrome browser cho image. 
- Cu·ªëi c√πng l√† Copy c√°c file v√†o docker image

B·∫°n c√≥ th·ªÉ ƒë·ªçc dockerfile c·ªßa m√¨nh ·ªü ƒë√¢y

```dockerfile
# based image: Ubuntubased. BTW, for the PYTHON:3.9 like you used last time. It used the Debianbased image

FROM public.ecr.aws/docker/library/ubuntu:22.04

# install a few things
RUN apt-get update && apt-get install -y \
    bash \
    git \
    curl \
    software-properties-common \
    pip \
    && rm -rf /var/lib/apt/lists/*

# workdir
WORKDIR /srv

# okay now pip
RUN apt-get -y update
RUN pip install --upgrade pip

# Copy the requirements.txt file first, for separate dependency resolving and downloading
COPY requirements.txt .
RUN pip install -r requirements.txt

# Install chrome broswer
RUN curl -sS -o - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -
RUN echo "deb http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list
RUN apt-get -y update
RUN apt-get -y install google-chrome-stable

# add the main.py
COPY main.py .

# add scraper
COPY scraper.py .

# add job_description_analyzer
COPY job_description_analyzer.py .

ENTRYPOINT [ "python3" , "main.py" ]
```
### 3. buildspec.yml
C√≤n 1 file n·ªØa m√† b·∫°n c·∫ßn ch√∫ √Ω, ƒë√≥ l√† file **buildspec.yml**. File n√†y c·ª±c k√¨ quan tr·ªçng, v√¨ n√≥ h∆∞·ªõng d·∫´n cho AWS Codebuild c√°ch build image c·ªßa b·∫°n. Buildspec ƒë∆∞·ª£c chia l√†m 3 phase, pre_build, build v√† post_build. 

```yaml
version: 0.2

phases:
  pre_build:
    commands:
      - echo "Logging in to ECR"
      - aws --version
      - AWS_DEFAULT_REGION=us-east-1
      - AWS_ACCOUNT_ID=238101178196
      - IMAGE_TAG=latest
      - REPOSITORY_URI=238101178196.dkr.ecr.us-east-1.amazonaws.com/indeed-scraper
      - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com

  build:
    commands:
      - echo "Building the Docker image..."
      - docker build -t $REPOSITORY_URI:$IMAGE_TAG .
      - docker push $REPOSITORY_URI:$IMAGE_TAG

  post_build:
    commands:
      - echo "Updating ECS service..."
      - echo "End of script"

artifacts:
  files:
    - '**/*'
  name: artifacts
```

Trong phase **pre_build**, m√¨nh ƒë√£ l∆∞u c√°c bi·∫øn m√¥i tr∆∞·ªùng nh∆∞ sau:

- **AWS_DEFAULT_REGION:** region m√† b·∫°n d√πng cho b√†i workshop n√†y, m√¨nh d√πng us-east-1 (virginia)
- **AWS_ACCOUNT_ID:** Account ID t√†i kho·∫£n AWS c·ªßa ban, c√≥ th·ªÉ t√¨m ƒë∆∞·ª£c ·ªü ph·∫ßn account
![lol](/images/2023-07-09-09-52-36.png)
- **IMAGE_TAG**: Tag c·ªßa image m√† b·∫°n mu·ªën l·∫•y trong ECR. Trong qu√° tr√¨nh build, b·∫°n s·∫Ω update image nhi·ªÅu l·∫ßn, m·ªói l·∫ßn l√† tag + 1. N√™n tag latest gi√∫p b·∫°n l·∫•y image m·ªõi nh·∫•t
- **REPOSITORY_URI:** link c·ªßa ECR repo ch·ª©a image, m√¨nh s·∫Ω t·∫°o ngay ·ªü ph√≠a d∆∞·ªõi.
- D√≤ng cu·ªëi c√πng c·ªßa phase l√† ƒë·ªÉ m√¨nh authenticate script c·ªßa m√¨nh, gi√∫p m√¨nh c√≥ th·ªÉ th·ª±c hi·ªán c√°c l·ªánh trong Docker nh∆∞ Push hay Pull image t·ª´ Ecr.
  
Trong phase **build**, m√¨nh s·∫Ω build image v√† push l√™n ECR repo. 

- `docker build -t $REPOSITORY_URI:$IMAGE_TAG .` m√¨nh build image v√† set tag l√† **latest**. ƒê√¢y l√† bi·∫øn IMAGE_TAG m√¨nh set t·ª´ tr∆∞·ªõc. Nh·ªõ ƒë·ª´ng qu√™n c√≥ 1 d·∫•u ch·∫•m sau ch·ªØ IMAGE_TAG ƒë·∫•y.
- `docker push $REPOSITORY_URI:$IMAGE_TAG` m√¨nh push Docker image m√¨nh v·ª´a build l√™n Ecr repo. ·ªû ƒëo·∫°n n√†y, n·∫øu l√†m theo m√¨nh th√¨ b·∫°n s·∫Ω b·ªã v∆∞·ªõn m·∫Øc do m√¨nh ch∆∞a t·∫°o repo, v√¨ v·∫≠y b·∫°n c√≥ th·ªÉ ƒë·ªÉ tr·ªëng bi·∫øn n√†y, v√† ƒë·ªçc ti·∫øp ph·∫ßn sau ƒë·ªÉ bi·∫øt c√°ch t·∫°o repo.
  
Cu·ªëi c√πng l√† phase **post_build**. M√¨nh ch·ªâ log ra console ƒë·ªÉ th√¥ng b√°o ho√†n th√†nh. Phase n√†y ho√†n to√†n kh√¥ng th·ª±c hi·ªán l·ªánh g√¨ c·∫£.

## Deploy Github repo l√™n Github.
Sau khi ho√†n th√†nh vi·ªác chu·∫©n b·ªã c√°c file, vi·ªác ti·∫øp theo l√† ƒë·∫©y repo l√™n Github. ƒê·∫ßu ti√™n, b·∫°n c·∫ßn m·ªü folder m√† b·∫°n v·ª´a clone repo v·ªÅ. Trong VSCode s·∫Ω nh√¨n nh∆∞ th·∫ø n√†y
![](/images/2023-07-19-18-32-06.png)

1. Ki·ªÉm tra xem b·∫°n ƒë√£ c√≥ git ch∆∞a b·∫±ng `git --version`. Ti·∫øp ƒë·∫øn, b·∫°n c·∫ßn remove file **.git** kh·ªèi folder do folder v·∫´n li√™n k·∫øt v·ªõi repo Github c·ªßa m√¨nh. D√πng l·ªánh n√†y ƒë·ªÉ remove file .git `rm -rf .git`. Sau ƒë√≥ b·∫°n c·∫ßn t·∫°o repo m·ªõi tr√™n Github c·ªßa m√¨nh. 
2. `git init -b main` ƒë·ªÉ kh·ªüi t·∫°o repo m·ªõi. 
3. `git add .` ƒë·ªÉ add t·∫•t c·∫£ c√°c file trong folder v√†o repo
4. `git commit -m "Initial commit"` ƒë·ªÉ commit c√°c file v·ª´a add v√†o repo
5. L√™n t√†i kho·∫£n github c·ªßa b·∫°n, t·∫°o 1 repo m·ªõi v√† copy URL 
6. `git remote add origin <URL>` ƒë·ªÉ add repo m·ªõi v√†o local repo c·ªßa b·∫°n
7. `git push -u origin main` ƒë·ªÉ push repo l√™n Github. N·∫øu b·∫°n b·ªã l·ªói, h√£y th·ª≠ `git push -f origin main` ƒë·ªÉ force push.
8. Sau khi push xong, b·∫°n c√≥ th·ªÉ th·∫•y repo c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c update